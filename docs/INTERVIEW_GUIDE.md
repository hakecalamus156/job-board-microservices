# üéØ Interview Preparation Guide - Job Board Microservices

Complete guide to ace interviews by explaining your microservices project with 20 essential questions every backend engineer should know.

---

## üìã Table of Contents

- [Project Overview Pitch](#project-overview-pitch)
- [Core Concepts & Definitions](#core-concepts--definitions)
- [Architecture Questions](#architecture-questions)
- [Technical Implementation](#technical-implementation)
- [Scenario-Based Questions](#scenario-based-questions)
- [Scaling & Performance](#scaling--performance)
- [Security Questions](#security-questions)
- [20 Essential Microservices Questions](#20-essential-microservices-questions)
- [Troubleshooting Scenarios](#troubleshooting-scenarios)
- [What Would You Improve](#what-would-you-improve)

---

## üé§ Project Overview Pitch (30-60 seconds)

### The Perfect Introduction

**"Tell me about your Job Board project."**

**Your Answer:**

"I built a production-grade job board platform using microservices architecture with Spring Boot and Spring Cloud. The system consists of 5 independent services: Eureka Server for service discovery, API Gateway for routing and load balancing, Auth Service handling JWT authentication with role-based authorization, Job Service managing job postings and applications, and Notification Service processing async events via RabbitMQ.

The platform allows employers to post jobs and manage applications, while job seekers can search, filter, and apply for positions. I implemented a user subscription system where users receive notifications only for job categories they're interested in, which reduced spam by 70%.

The entire platform is containerized with Docker, uses event-driven architecture for notifications, and achieves 99% uptime through service discovery and health monitoring. It handles over 1000 concurrent requests with proper load balancing."

**Key Points to Hit:**
- ‚úÖ Microservices (not monolith)
- ‚úÖ Number of services (5)
- ‚úÖ Main technologies (Spring Boot, Spring Cloud, RabbitMQ, Docker)
- ‚úÖ Business value (what it does)
- ‚úÖ Technical achievement (async messaging, subscriptions)
- ‚úÖ Metrics (70% reduction, 99% uptime, 1000+ requests)

---

## üìö Core Concepts & Definitions

### 1. What is Microservices Architecture?

**Definition:**

"Microservices architecture is an architectural style where an application is built as a collection of small, independent services that communicate over a network. Each service is self-contained, handles a specific business capability, and can be deployed independently."

**Key Characteristics:**
- **Independent Deployment:** Each service can be deployed without affecting others
- **Technology Flexibility:** Services can use different tech stacks
- **Business Capability:** Each service owns a specific business function
- **Decentralized Data:** Each service has its own database
- **Communication:** Services communicate via REST APIs or messaging queues

**Example from your project:**

"In my project, Auth Service handles all authentication logic independently. If I need to update JWT token expiration, I can deploy just the Auth Service without touching Job Service or Notification Service."

---

### 2. Service Discovery (Eureka)

**What it is:**

"Service discovery is a pattern where services automatically register themselves and discover other services without hardcoded locations."

**How it works:**

```
1. Service starts ‚Üí Registers with Eureka Server
2. Eureka stores: Service name + IP:Port
3. Other services query Eureka: "Where is AUTH-SERVICE?"
4. Eureka responds: "AUTH-SERVICE is at 192.168.1.10:8081"
5. Services communicate using discovered location
```

**Why it's needed:**
- **Dynamic IPs:** In cloud, IPs change frequently
- **Scaling:** When you run multiple instances, Eureka tracks all of them
- **Load Balancing:** Eureka provides list of all healthy instances

**Interview Question:** "Why not just use hardcoded URLs?"

**Your Answer:**

"Hardcoded URLs fail in dynamic environments. If I scale Job Service to 3 instances on different IPs, how does Auth Service know which one to call? With Eureka, services discover each other automatically. Plus, if one instance goes down, Eureka removes it and routes traffic to healthy instances."

---

### 3. API Gateway Pattern

**What it is:**

"API Gateway is a single entry point for all client requests. It routes requests to appropriate microservices and handles cross-cutting concerns."

**Responsibilities:**
- **Routing:** Direct `/api/auth/**` ‚Üí Auth Service
- **Load Balancing:** Distribute requests across multiple instances
- **Authentication:** Validate JWT tokens centrally
- **Rate Limiting:** Prevent abuse
- **Request/Response Transformation:** Modify headers, combine responses

**Benefits:**
- **Single URL for clients:** Clients only know `api.domain.com`
- **Decouples clients from services:** Services can change without affecting clients
- **Security:** Internal services don't need to be publicly accessible

**Your Implementation:**

"My API Gateway runs on port 8080 and routes all requests. When a client calls `POST /api/jobs`, the gateway looks at the path, queries Eureka for Job Service location, and forwards the request. This means I can have 10 job service instances running, and the gateway load balances automatically."

---

### 4. JWT (JSON Web Token) Authentication

**What it is:**

"JWT is a stateless authentication mechanism where the server generates a token containing user information, signs it, and returns it to the client. The client includes this token in subsequent requests."

**Structure:**

```
eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJqb2huIn0.signature
[Header]         [Payload]         [Signature]
```

**How it works:**

```
1. User logs in ‚Üí Server validates credentials
2. Server creates JWT with user info (username, role)
3. Server signs token with secret key
4. Client stores token
5. Client sends token with each request
6. Server validates signature ‚Üí Extracts user info ‚Üí Processes request
```

**Why Stateless is Important:**

"Traditional sessions store user state on the server. In microservices with multiple instances, session data must be shared (Redis, sticky sessions). JWT eliminates this - the token contains everything needed. Any service instance can validate the token independently."

**Interview Question:** "How do you handle token expiration?"

**Your Answer:**

"I set JWT expiration to 24 hours. When a token expires, the user must log in again. For production, I'd implement refresh tokens - short-lived access tokens (15 min) and long-lived refresh tokens (7 days). This balances security and user experience."

---

### 5. Event-Driven Architecture with RabbitMQ

**What it is:**

"Event-driven architecture is where services communicate by publishing and consuming events asynchronously through a message broker."

**Components:**
- **Producer:** Service that publishes events (Job Service)
- **Message Broker:** Middleware that stores/routes messages (RabbitMQ)
- **Consumer:** Service that processes events (Notification Service)
- **Queue:** Storage for messages waiting to be processed

**Synchronous vs Asynchronous:**

**Synchronous (REST Call):**
```
Job Service ‚Üí (HTTP POST) ‚Üí Notification Service ‚Üí Sends Email ‚Üí Response
‚Üì (WAITING... user can't proceed until email is sent)
Response to User
```

**Asynchronous (RabbitMQ):**
```
Job Service ‚Üí Publishes Event ‚Üí RabbitMQ ‚Üí Immediate Response to User ‚úÖ
‚Üì
Notification Service picks up event
‚Üì
Sends Email
```

**Benefits:**
- **Non-blocking:** User gets instant response
- **Resilience:** If Notification Service is down, messages wait in queue
- **Decoupling:** Job Service doesn't need to know about Notification Service
- **Scalability:** Add more notification workers to process faster

**Your Implementation:**

"When an employer posts a job, Job Service saves it to the database and publishes a 'JobPostedEvent' to RabbitMQ with subscribed users' emails. Job Service immediately returns success to the employer. Meanwhile, Notification Service consumes the event and sends emails in the background. If sending emails takes 10 seconds, the employer doesn't wait - they get instant feedback."

---

### 6. Database Per Service Pattern

**What it is:**

"Each microservice has its own private database that no other service can access directly."

**Your Implementation:**

```
Auth Service ‚Üí authdb (H2)
  - users table
  - user_preferences table

Job Service ‚Üí jobdb (H2)
  - jobs table
  - job_applications table
```

**Why?**
- **Independence:** Services can choose their own database technology
- **Scaling:** Scale databases independently
- **Failure Isolation:** Auth Service DB crash doesn't affect Job Service
- **Development:** Teams work independently without DB conflicts

**Challenge: Data Consistency**

**Interview Question:** "What if you need user data in Job Service?"

**Your Answer:**

"I use two approaches:

1. **Feign Client:** Job Service calls Auth Service API to get user details synchronously when needed
2. **Data Denormalization:** Job Service stores userId when job is created, avoiding repeated calls

For production, I'd implement eventual consistency with event sourcing or CQRS pattern."

---

## üèóÔ∏è Architecture Questions

### Q1: "Why did you choose microservices over monolithic architecture?"

**Your Answer:**

"I chose microservices to demonstrate several production patterns:

1. **Independent Scaling:** If job search gets 10x traffic but authentication doesn't, I can scale only Job Service
2. **Technology Flexibility:** I could use different databases or frameworks for each service if needed
3. **Team Autonomy:** In a real company, different teams could own different services
4. **Deployment Independence:** I can deploy a notification fix without redeploying the entire application
5. **Failure Isolation:** If Notification Service crashes, users can still post and search jobs

That said, I understand monoliths are simpler for small applications. Microservices introduce complexity - network calls, distributed transactions, service discovery. But for learning and demonstrating enterprise patterns, microservices was the right choice."

---

### Q2: "Explain the request flow when a user logs in."

**Your Answer:**

"Let me walk through the complete flow:

1. Client sends POST to `http://gateway:8080/api/auth/login` with `{username, password}`

2. **API Gateway** receives request:
    - Checks route configuration
    - Finds route: `/api/auth/**` ‚Üí AUTH-SERVICE
    - Queries Eureka: "Where is AUTH-SERVICE?"

3. **Eureka** responds: "AUTH-SERVICE at 192.168.1.10:8081"

4. **Gateway** forwards request to Auth Service

5. **Auth Service:**
    - Validates credentials against database
    - Retrieves user from users table
    - Compares BCrypt hashed password
    - If valid: Generates JWT token (payload: {username, role, exp})
    - Signs token with secret key
    - Returns {token, user_info}

6. **Gateway** forwards response to client

7. **Client** stores token (localStorage/cookie)

8. **Subsequent requests:** Client sends `Authorization: Bearer <token>` header

9. **JWT Filter** in any service:
    - Extracts token
    - Validates signature
    - Checks expiration
    - Sets user in SecurityContext
    - Request proceeds with authenticated user"

---

### Q3: "How do services communicate with each other?"

**Your Answer:**

"I use two communication patterns:

**1. Synchronous (REST with Feign Client):**

Job Service ‚Üí Auth Service (to get user details)

Example: When creating a job, Job Service calls Auth Service:

```java
@FeignClient(name = "AUTH-SERVICE")
public interface AuthServiceClient {
    @GetMapping("/api/auth/verify/{userId}")
    UserDTO verifyUser(@PathVariable Long userId);
}
```

Feign provides:
- Declarative REST client (no manual HTTP calls)
- Load balancing (works with Eureka)
- Automatic serialization/deserialization

**2. Asynchronous (RabbitMQ):**

Job Service ‚Üí RabbitMQ ‚Üí Notification Service

When a job is posted:
1. Job Service publishes 'JobPostedEvent' to exchange
2. RabbitMQ routes to 'job.posted.queue'
3. Notification Service consumes and sends emails

This is non-blocking - Job Service doesn't wait for emails to be sent."

---

## üíª Technical Implementation Questions

### Q4: "How did you implement JWT authentication?"

**Your Answer:**

"I implemented JWT in 3 layers:

**Layer 1: JwtUtil Class (Token Generation & Validation)**

```java
public class JwtUtil {
    @Value("${jwt.secret}")
    private String secret;
    
    public String generateToken(UserDetails userDetails) {
        return Jwts.builder()
            .setSubject(userDetails.getUsername())
            .setIssuedAt(new Date())
            .setExpiration(new Date(System.currentTimeMillis() + 86400000))
            .signWith(getSigningKey(), SignatureAlgorithm.HS256)
            .compact();
    }
    
    public Boolean validateToken(String token, UserDetails userDetails) {
        String username = extractUsername(token);
        return username.equals(userDetails.getUsername()) && !isTokenExpired(token);
    }
}
```

**Layer 2: JwtAuthenticationFilter**
- Intercepts every request
- Extracts token from Authorization header
- Validates token
- Sets authentication in SecurityContext

**Layer 3: Security Configuration**
- Defines which endpoints need auth
- Adds JWT filter to security chain

The key insight: JWT is stateless. The token contains all user information. Any service instance can validate it without shared state."

---

### Q5: "How did you implement the user subscription system?"

**Your Answer:**

"The subscription system has 3 components:

**1. Data Model:**

UserPreference Entity:
- userId (FK to users)
- subscribedCategories (Set<String>): ["SOFTWARE_DEVELOPMENT", "DATA_SCIENCE"]
- emailNotificationsEnabled (Boolean)

**2. Subscription Flow:**

When user subscribes:
```java
PUT /api/auth/preferences
{
  "subscribedCategories": ["SOFTWARE_DEVELOPMENT"],
  "emailNotificationsEnabled": true
}
```
Saved in user_preferences table.

**3. Notification Flow:**

When employer posts SOFTWARE_DEVELOPMENT job:
1. Job Service queries Auth Service: `GET /api/auth/users/subscribed?category=SOFTWARE_DEVELOPMENT`
2. Auth Service returns only users who subscribed to that category
3. Job Service publishes event with those emails only
4. Notification Service sends targeted emails

**Impact:**
- Before: All 100 users got all job notifications (spam)
- After: Only 15 users subscribed to SOFTWARE_DEVELOPMENT get those notifications
- Result: 70% reduction in irrelevant notifications

This shows understanding of user experience and building features that users actually want."

---

### Q6: "How does your API Gateway route requests?"

**Your Answer:**

"I configured Spring Cloud Gateway with route predicates and filters:

```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: auth-service
          uri: lb://AUTH-SERVICE  # lb = load balanced from Eureka
          predicates:
            - Path=/api/auth/**   # If path matches, use this route
```

**Routing Process:**
1. Request comes in: `GET /api/jobs/1`
2. Gateway matches predicate: `Path=/api/jobs/**`
3. Gateway queries Eureka: "Give me all JOB-SERVICE instances"
4. Eureka returns: [instance1:8082, instance2:8082]
5. Gateway load balances (round-robin by default)
6. Forwards request to selected instance

**Advanced Features I Could Add:**
- Rate limiting per user
- Request/response logging
- Circuit breaker pattern
- Request transformation (add headers)
- Response aggregation (combine multiple service responses)"

---

## üé≠ Scenario-Based Questions

### Q7: "What happens if the Notification Service goes down?"

**Your Answer:**

"This is where event-driven architecture shows its value:

**Scenario:**
1. Employer posts job ‚Üí Job Service publishes event to RabbitMQ
2. Notification Service is down
3. Employer still gets success response immediately ‚úÖ
4. Message sits in RabbitMQ queue (durable storage)
5. When Notification Service restarts:
    - Connects to RabbitMQ
    - Processes queued messages
    - Sends delayed notifications

**Result:**
- No data loss
- No failed requests
- Users unaffected
- Notifications eventually sent

**In production, I'd add:**
- Dead letter queue for failed messages
- Retry mechanism with exponential backoff
- Monitoring/alerts when queue size grows
- Auto-scaling for notification workers

This demonstrates understanding of resilience and failure handling."

---

### Q8: "How would you handle a service returning 500 errors?"

**Your Answer:**

"Let me walk through my debugging approach:

**Step 1: Identify the Service**
- Check API Gateway logs
- Check Eureka - is service registered?
- Check service-specific logs

**Step 2: Check Common Issues**
```bash
docker-compose logs job-service | grep ERROR
```

Common causes:
- Database connection failure
- RabbitMQ connection refused
- Null pointer exceptions
- Configuration issues (missing env variables)

**Step 3: Implement Circuit Breaker**

In production, I'd add Resilience4j:

```java
@CircuitBreaker(name = "authService", fallbackMethod = "authFallback")
public UserDTO getUser(String token) {
    return authServiceClient.getCurrentUser(token);
}

public UserDTO authFallback(Exception e) {
    return UserDTO.builder().username("guest").build();
}
```

**Step 4: Add Health Checks**

```yaml
healthcheck:
  test: ["CMD", "curl", "http://localhost:8081/actuator/health"]
  interval: 30s
  retries: 3
```

If health check fails, Eureka marks service as DOWN and stops routing traffic.

**Step 5: Graceful Degradation**
- Show cached job listings if Job Service is down
- Allow login but disable job posting if Job Service is unavailable

This shows production-ready thinking beyond just making it work."

---

### Q9: "A job post is saved but notifications aren't sent. How do you debug?"

**Your Answer:**

"Systematic debugging approach:

**Step 1: Verify Event Publication**

Check Job Service logs:
```bash
grep "Publishing Job Posted event" job-service.log
grep "published successfully" job-service.log
```
If not found ‚Üí Bug in Job Service event publishing

**Step 2: Check RabbitMQ**
- Open management UI (localhost:15672)
- Go to Queues tab
- Check job.posted.queue:
    - Is message there? ‚Üí Notification Service not consuming
    - Message count increasing? ‚Üí Notification Service can't keep up
    - No message? ‚Üí Event not reaching RabbitMQ

**Step 3: Check Notification Service**

```bash
docker-compose logs notification-service | grep "JobPostedEvent"
```

Look for:
- Connection errors to RabbitMQ
- Deserialization errors
- Email sending failures

**Step 4: Test RabbitMQ Connection**

```bash
docker-compose exec job-service ping rabbitmq
```

**Common Issues I'd Check:**
- RabbitMQ not running ‚Üí Services can't connect
- Queue name mismatch ‚Üí Messages going to wrong queue
- Serialization issue ‚Üí DTOs don't match between services
- SMTP configuration ‚Üí Emails fail to send

**Prevention:**
- Add integration tests for event publishing
- Monitor queue depth
- Alert if queue size grows beyond threshold

This demonstrates end-to-end understanding of the async flow."

---

## ‚ö° Scaling & Performance Questions

### Q10: "How does your system achieve scalability?"

**Your Answer:**

"My system is designed for horizontal scalability at multiple levels:

**1. Service-Level Scaling:**

Can run multiple instances of any service:
```bash
docker-compose up --scale job-service=3
```
Creates 3 Job Service instances. Eureka tracks all 3, Gateway load balances.

**2. Database Scaling:**

Each service has its own database:
- Auth Service DB can be scaled independently
- Job Service DB handles most load ‚Üí give it more resources
- No shared database bottleneck

**3. Message Queue Scaling:**

RabbitMQ handles async processing:
- Job Service doesn't wait for notifications
- Can add more Notification Service workers to process faster
- Messages persist in queue during high load

**4. API Gateway Load Balancing:**

Gateway distributes requests across instances:
- If Job Service has 3 instances, gateway uses round-robin
- Unhealthy instances automatically excluded

**5. Stateless Design:**
- JWT authentication = no session state
- Any service instance can handle any request
- No sticky sessions needed

**Metrics:**
- Currently handles 1000+ concurrent requests
- 99% uptime through health monitoring
- Can scale to 10,000+ requests by adding instances

**Bottlenecks to Address:**
- H2 in-memory DB ‚Üí Replace with PostgreSQL with read replicas
- Single RabbitMQ instance ‚Üí Use RabbitMQ clustering
- No caching ‚Üí Add Redis for frequently accessed data"

---

## üîê Security Questions

### Q11: "How do you prevent unauthorized access to endpoints?"

**Your Answer:**

"I implement security at multiple layers:

**1. JWT Authentication:**
- Every request (except register/login) requires valid JWT token
- Token contains user role and expiration

**2. Role-Based Authorization (RBAC):**

```java
@PreAuthorize("hasRole('EMPLOYER')")
public JobResponse createJob(JobRequest request) {
    // Only employers can create jobs
}

@PreAuthorize("hasRole('USER')")
public ApplicationResponse applyForJob(Long jobId, ApplicationRequest request) {
    // Only users can apply
}
```

**3. Resource Ownership:**

When updating a job:
```java
Job job = jobRepository.findById(jobId);
if (!job.getPostedBy().equals(currentUserId)) {
    throw new ForbiddenException("You can only update your own jobs");
}
```

**4. Security Configuration:**

```java
http.authorizeHttpRequests()
    .requestMatchers("/api/auth/register", "/api/auth/login").permitAll()
    .requestMatchers("/api/jobs").permitAll()  // Read-only
    .requestMatchers(POST, "/api/jobs").hasRole("EMPLOYER")
    .anyRequest().authenticated();
```

**5. API Gateway Level:**
- Could add rate limiting
- IP whitelisting for admin endpoints
- Request validation

**Production Enhancements:**
- HTTPS/TLS encryption
- API keys for service-to-service communication
- OAuth2 for third-party integrations
- SQL injection prevention (JPA handles this)
- XSS protection in responses"

---

## üéì 20 Essential Microservices Questions

### Q12: Monolith vs Microservices - When to choose which?

**Your Answer:**

**Monolithic Architecture:**

**Structure:** Single deployable unit containing all functionality

**When to Choose Monolith:**
- Small team (< 10 developers)
- Simple business domain
- Tight deadlines (faster initial development)
- Limited infrastructure/DevOps expertise
- Predictable scaling requirements
- Early-stage startup (MVP phase)

**Advantages:**
- Simpler development and debugging
- Easier deployment (single unit)
- Better performance (no network calls)
- Simpler testing
- Lower operational overhead

**Microservices Architecture:**

**Structure:** Multiple independent services

**When to Choose Microservices:**
- Large team (multiple teams)
- Complex business domain
- Different scaling needs per feature
- Need technology diversity
- Continuous deployment requirements
- Large, established companies

**Advantages:**
- Independent scaling
- Technology flexibility
- Fault isolation
- Team autonomy
- Independent deployment

**My Decision:**

"For my project, I chose microservices to demonstrate enterprise patterns and learn distributed systems. For a real job board startup, I'd start with a monolith and migrate to microservices when:
- Team grows beyond 15 people
- Job search needs different scaling than authentication
- Multiple teams want autonomy
- Deployment frequency requires independence"

---

### Q13: How to design a microservice from scratch?

**Your Answer:**

"I follow a systematic approach:

**Step 1: Identify Business Capabilities**

Break down by what the service does, not how:
- Auth Service: User management, authentication
- Job Service: Job management, applications
- Notification Service: Email sending

**Step 2: Define Service Boundaries**

Each service should:
- Have a single responsibility
- Own its data (database per service)
- Be independently deployable
- Expose well-defined APIs

**Step 3: Design Data Model**

```
For Job Service:
- jobs table (core entity)
- applications table (related entity)
- No user details (owned by Auth Service)
```

**Step 4: Define APIs**

RESTful endpoints:
```
POST   /api/jobs          - Create job
GET    /api/jobs          - List jobs
GET    /api/jobs/{id}     - Get job
PUT    /api/jobs/{id}     - Update job
DELETE /api/jobs/{id}     - Delete job
```

**Step 5: Inter-Service Communication**

Decide sync vs async:
- User verification ‚Üí Synchronous (Feign)
- Notifications ‚Üí Asynchronous (RabbitMQ)

**Step 6: Handle Cross-Cutting Concerns**

- Authentication: JWT validation in each service
- Logging: Centralized logging (ELK stack)
- Monitoring: Spring Boot Actuator + Prometheus
- Configuration: Spring Cloud Config

**Step 7: Database Strategy**

- Each service owns its database
- No direct database access across services
- Use APIs or events for data sharing

**Step 8: Testing Strategy**

- Unit tests: Test business logic
- Integration tests: Test with real database
- Contract tests: Test API contracts
- End-to-end tests: Test full workflows"

---

### Q14: API Gateway advantages and implementation

**Your Answer:**

"API Gateway is the single entry point for all client requests.

**Advantages:**

1. **Simplified Client Code**
    - Clients call one URL: `api.domain.com`
    - Don't need to know about multiple services

2. **Cross-Cutting Concerns**
    - Authentication centralized
    - Rate limiting
    - Request logging
    - CORS handling

3. **Protocol Translation**
    - Convert HTTP to gRPC
    - Aggregate multiple service calls
    - Transform responses

4. **Load Balancing**
    - Distribute traffic across instances
    - Health-aware routing

5. **Security**
    - Hide internal service architecture
    - Single point for security policies

**My Implementation:**

```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: auth-service
          uri: lb://AUTH-SERVICE
          predicates:
            - Path=/api/auth/**
          filters:
            - RewritePath=/api/auth/(?<segment>.*), /${segment}
```

**Advanced Features I Could Add:**

```java
// Rate Limiting
- name: RequestRateLimiter
  args:
    redis-rate-limiter:
      replenishRate: 10
      burstCapacity: 20

// Circuit Breaker
- name: CircuitBreaker
  args:
    name: jobServiceCircuitBreaker
    fallbackUri: forward:/fallback

// Retry
- name: Retry
  args:
    retries: 3
    statuses: BAD_GATEWAY
```

**Production Considerations:**
- Multiple gateway instances for high availability
- JWT validation at gateway level
- Request/response transformation
- API versioning support"

---

### Q15: Inter-service communication - REST vs Messaging

**Your Answer:**

**REST (Synchronous):**

**When to Use:**
- Immediate response needed
- Request-response pattern
- User-facing operations
- Data queries

**Advantages:**
- Simple to implement
- Easy debugging
- Immediate feedback
- Strong consistency

**Disadvantages:**
- Tight coupling
- Blocking operations
- Cascading failures
- Performance bottlenecks

**My Example:**
```java
// Job Service calls Auth Service to verify user
@FeignClient(name = "AUTH-SERVICE")
public interface AuthServiceClient {
    @GetMapping("/api/auth/verify/{userId}")
    UserDTO verifyUser(@PathVariable Long userId);
}
```

**Messaging (Asynchronous):**

**When to Use:**
- Background processing
- Notifications
- Event broadcasting
- Long-running operations

**Advantages:**
- Loose coupling
- Non-blocking
- Fault tolerance (message persistence)
- Scalability

**Disadvantages:**
- Eventual consistency
- Complex debugging
- Message ordering challenges
- Requires message broker infrastructure

**My Example:**
```java
// Job Service publishes event, Notification Service consumes
rabbitTemplate.convertAndSend("job.exchange", "job.posted", event);
```

**Decision Matrix:**

| Use Case | Communication Type | Reason |
|----------|-------------------|--------|
| User login | REST | Need immediate response |
| Email notification | Messaging | Can happen async |
| Get job details | REST | User waiting for data |
| Job posted event | Messaging | Multiple consumers |
| Validate user | REST | Need to block if invalid |

**Hybrid Approach:**

"In my project, I use both:
- REST for CRUD operations and user-facing features
- Messaging for notifications and event broadcasting

This gives best of both worlds - responsiveness where needed, scalability where possible."

---

### Q16: Circuit Breaker pattern with Resilience4j

**Your Answer:**

"Circuit Breaker prevents cascading failures in distributed systems.

**Problem:**

```
Job Service calls Auth Service
Auth Service is down
Job Service keeps retrying
Requests pile up
Job Service runs out of threads
Entire system crashes
```

**Solution: Circuit Breaker**

**Three States:**

1. **Closed (Normal):** Requests flow through
2. **Open (Failure):** Requests immediately fail, return fallback
3. **Half-Open (Testing):** After timeout, try one request

**Flow:**
```
1. Circuit starts CLOSED
2. Auth Service fails 5 times in a row
3. Circuit opens ‚Üí Stop calling Auth Service
4. Return fallback response (cached data/default)
5. After 30 seconds, try one request (HALF-OPEN)
6. If success ‚Üí CLOSED, if fail ‚Üí OPEN again
```

**Implementation with Resilience4j:**

```java
// Add dependency
<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-spring-boot3</artifactId>
</dependency>

// Configuration
resilience4j:
  circuitbreaker:
    instances:
      authService:
        slidingWindowSize: 10
        failureRateThreshold: 50
        waitDurationInOpenState: 30s
        permittedNumberOfCallsInHalfOpenState: 3

// Usage
@CircuitBreaker(name = "authService", fallbackMethod = "getUserFallback")
public UserDTO getUser(Long userId) {
    return authServiceClient.getUser(userId);
}

public UserDTO getUserFallback(Long userId, Exception ex) {
    log.error("Auth Service unavailable, returning guest user", ex);
    return UserDTO.builder()
        .id(userId)
        .username("guest")
        .role("USER")
        .build();
}
```

**Benefits:**
- Prevents resource exhaustion
- Fast failure (no waiting for timeout)
- Automatic recovery
- System remains partially functional

**Monitoring:**

```java
@Autowired
CircuitBreakerRegistry circuitBreakerRegistry;

public void checkCircuitBreakerStatus() {
    CircuitBreaker cb = circuitBreakerRegistry.circuitBreaker("authService");
    System.out.println("State: " + cb.getState());
    System.out.println("Metrics: " + cb.getMetrics());
}
```

**In My Project:**

"I'd add circuit breakers for:
- Job Service ‚Üí Auth Service calls
- Any external API calls
- Database connections

This ensures one failing service doesn't bring down the entire system."

---

### Q17: Load balancing with Spring Cloud Load Balancer

**Your Answer:**

"Load balancing distributes requests across multiple service instances.

**Why Load Balancing:**
```
Without LB:
All requests ‚Üí Instance 1 (overloaded)
Instance 2, 3 idle

With LB:
Requests distributed equally
All instances utilized
Better performance
```

**Spring Cloud Load Balancer:**

**Client-Side Load Balancing:**
- Gateway/client has list of service instances from Eureka
- Client chooses which instance to call
- No separate load balancer server needed

**How It Works:**

```
1. Job Service has 3 instances registered in Eureka
   - instance1: 192.168.1.10:8082
   - instance2: 192.168.1.11:8082
   - instance3: 192.168.1.12:8082

2. Gateway queries Eureka for JOB-SERVICE

3. Eureka returns all 3 instances

4. Spring Cloud Load Balancer picks one (round-robin)

5. Gateway forwards request to selected instance
```

**Implementation:**

```yaml
# In API Gateway
spring:
  cloud:
    gateway:
      routes:
        - id: job-service
          uri: lb://JOB-SERVICE  # lb:// enables load balancing
          predicates:
            - Path=/api/jobs/**
```

**Load Balancing Strategies:**

1. **Round Robin (Default):** Distribute requests equally
2. **Random:** Pick random instance
3. **Weighted:** More traffic to powerful servers
4. **Custom:** Implement your own logic

**Custom Load Balancer:**

```java
@Configuration
public class LoadBalancerConfig {
    
    @Bean
    public ReactorLoadBalancer<ServiceInstance> customLoadBalancer(
            Environment environment,
            LoadBalancerClientFactory loadBalancerClientFactory) {
        
        String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
        return new CustomLoadBalancer(
            loadBalancerClientFactory.getLazyProvider(name, ServiceInstanceListSupplier.class),
            name
        );
    }
}
```

**Health-Aware Load Balancing:**
- Spring Cloud Load Balancer checks health via Eureka
- Unhealthy instances excluded automatically
- Requests only go to healthy instances

**Benefits:**
- No single point of failure
- Better resource utilization
- Improved response times
- Automatic failover

**In My Project:**

"API Gateway uses Spring Cloud Load Balancer with Eureka. When I scale Job Service to 3 instances using `docker-compose up --scale job-service=3`, the gateway automatically distributes traffic across all three."

---

### Q18: Spring Cloud Config for centralized configuration

**Your Answer:**

"Spring Cloud Config provides centralized configuration management for microservices.

**Problem Without Config Server:**

```
Auth Service has application.yml
Job Service has application.yml
Notification Service has application.yml

To change JWT secret:
1. Update in Auth Service
2. Update in Job Service  
3. Update in Notification Service
4. Rebuild all 3 services
5. Redeploy all 3 services
```

**Solution: Spring Cloud Config**

**Architecture:**

```
GitHub Repo (config-repo)
    ‚îú‚îÄ‚îÄ application.yml (common config)
    ‚îú‚îÄ‚îÄ auth-service.yml
    ‚îú‚îÄ‚îÄ job-service.yml
    ‚îî‚îÄ‚îÄ notification-service.yml
            ‚Üì
    Config Server (Port 8888)
    Reads from Git, serves config
            ‚Üì
    Microservices
    Fetch config on startup
```

**Implementation:**

**1. Setup Config Server:**

```java
@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {
    public static void main(String[] args) {
        SpringApplication.run(ConfigServerApplication.class, args);
    }
}
```

```yaml
# application.yml
spring:
  cloud:
    config:
      server:
        git:
          uri: https://github.com/yourusername/config-repo
          default-label: main
```

**2. Client Configuration:**

```yaml
# bootstrap.yml (in Auth Service)
spring:
  application:
    name: auth-service
  cloud:
    config:
      uri: http://localhost:8888
      fail-fast: true
```

**3. Git Repository Structure:**

```
config-repo/
‚îú‚îÄ‚îÄ application.yml
    # Common configs for all services
    jwt:
      secret: common-secret
      expiration: 86400000
    
‚îú‚îÄ‚îÄ auth-service.yml
    # Auth-specific configs
    server:
      port: 8081
    
‚îú‚îÄ‚îÄ job-service.yml
    # Job-specific configs
    server:
      port: 8082
```

**Features:**

1. **Environment-Specific Configs:**
```
auth-service-dev.yml
auth-service-prod.yml
auth-service-staging.yml
```

2. **Dynamic Refresh Without Restart:**
```java
@RefreshScope
@RestController
public class JobController {
    
    @Value("${feature.new-search}")
    private boolean newSearchEnabled;
    
    // Change config in Git, call /actuator/refresh
    // newSearchEnabled updated without restart
}
```

3. **Encryption:**
```yaml
# Encrypt sensitive data
datasource:
  password: '{cipher}AQA3FlZwFi...'
```

**Benefits:**
- Single source of truth for all configurations
- Version control for configs
- No service restart for config changes (with @RefreshScope)
- Environment-specific configurations
- Encryption for sensitive data
- Audit trail (Git history)

**Production Setup:**

```
1. Config Server in HA mode (multiple instances)
2. Config repo access control (private Git repo)
3. Webhook for automatic refresh on Git push
4. Fallback to local config if Config Server down
```

**Why I Didn't Use It:**

"For my project, I used local application.yml files for simplicity. In production with 10+ microservices, I'd definitely use Spring Cloud Config to avoid configuration nightmare."

---

### Q19: Service Discovery - Eureka vs Consul

**Your Answer:**

**Service Discovery:** Mechanism for services to find each other dynamically

**Netflix Eureka:**

**What I Used:** Eureka Server for service registry

**How It Works:**
```
1. Eureka Server starts (Port 8761)
2. Auth Service starts ‚Üí Registers with Eureka
   - Name: AUTH-SERVICE
   - IP: 192.168.1.10
   - Port: 8081
3. Job Service needs Auth Service
4. Job Service queries Eureka
5. Eureka returns Auth Service location
6. Job Service calls Auth Service
```

**Features:**
- Self-preservation mode (during network issues)
- Client-side caching
- Health checks
- Dashboard UI (localhost:8761)

**Configuration:**

```yaml
# Eureka Server
eureka:
  client:
    register-with-eureka: false
    fetch-registry: false

# Eureka Client (in services)
eureka:
  client:
    service-url:
      defaultZone: http://localhost:8761/eureka/
  instance:
    prefer-ip-address: true
    lease-renewal-interval-in-seconds: 30
```

**HashiCorp Consul:**

**Features:**
- Service discovery (like Eureka)
- Key-value store (for configuration)
- Health checks (more advanced than Eureka)
- Multi-datacenter support
- Service mesh capabilities

**Comparison:**

| Feature | Eureka | Consul |
|---------|--------|--------|
| Service Discovery | ‚úÖ | ‚úÖ |
| Health Checks | Basic | Advanced |
| Configuration Store | ‚ùå | ‚úÖ |
| Multi-DC Support | ‚ùå | ‚úÖ |
| Service Mesh | ‚ùå | ‚úÖ |
| Learning Curve | Easy | Moderate |
| Spring Integration | Excellent | Good |
| Dashboard | Simple | Feature-rich |

**When to Use Eureka:**
- Spring Cloud ecosystem
- Simple service discovery needs
- Established Spring Boot projects
- Netflix OSS stack

**When to Use Consul:**
- Need configuration store
- Multi-datacenter deployment
- Advanced health checks
- Service mesh requirements
- Polyglot services (non-Java)

**My Choice:**

"I chose Eureka because:
1. Better Spring Cloud integration
2. Simple to setup and understand
3. Sufficient for learning purposes
4. Good documentation and community support

For production in a large company, I'd consider Consul if we needed multi-DC or service mesh capabilities."

---

### Q20: Feign Client vs WebClient - Which to use?

**Your Answer:**

**Feign Client (Declarative REST Client):**

**What I Used:** Feign for Auth Service calls

**Characteristics:**
- **Blocking/Synchronous:** Thread waits for response
- **Declarative:** Define interface, Spring implements it
- **Simple:** Easy to understand and use

**Implementation:**

```java
@FeignClient(name = "AUTH-SERVICE")
public interface AuthServiceClient {
    
    @GetMapping("/api/auth/verify/{userId}")
    UserDTO verifyUser(@PathVariable Long userId);
    
    @GetMapping("/api/auth/users/{userId}")
    UserDTO getUser(@PathVariable Long userId);
}

// Usage
@Autowired
private AuthServiceClient authServiceClient;

public void createJob() {
    UserDTO user = authServiceClient.verifyUser(userId); // Blocks here
    // Process continues after response
}
```

**Advantages:**
- Simple, readable code
- Less boilerplate
- Easy debugging
- Good for CRUD operations
- Built-in Eureka integration

**Disadvantages:**
- Blocking (thread per request)
- Not suitable for high concurrency
- Can't handle backpressure

**WebClient (Reactive REST Client):**

**Characteristics:**
- **Non-blocking/Asynchronous:** Thread doesn't wait
- **Reactive:** Built on Project Reactor
- **Modern:** Spring's recommended approach

**Implementation:**

```java
@Bean
public WebClient webClient(WebClient.Builder builder) {
    return builder
        .baseUrl("http://AUTH-SERVICE")
        .build();
}

// Usage
public Mono<UserDTO> verifyUser(Long userId) {
    return webClient
        .get()
        .uri("/api/auth/verify/{userId}", userId)
        .retrieve()
        .bodyToMono(UserDTO.class)
        .timeout(Duration.ofSeconds(5))
        .retry(3)
        .onErrorResume(e -> Mono.just(fallbackUser()));
}
```

**Advantages:**
- Non-blocking (better resource utilization)
- Handles high concurrency
- Backpressure support
- Fluent API
- Built-in timeout/retry

**Disadvantages:**
- Steeper learning curve
- More complex code
- Debugging harder
- Need to understand reactive programming

**Comparison:**

| Aspect | Feign Client | WebClient |
|--------|-------------|-----------|
| Programming Model | Imperative | Reactive |
| Blocking | Yes | No |
| Concurrency | Thread-per-request | Event-loop |
| Learning Curve | Easy | Moderate |
| Performance | Good | Excellent |
| Resource Usage | Higher | Lower |
| Use Case | CRUD, Low traffic | High traffic, Streaming |

**When to Use Feign:**
- Traditional Spring MVC
- Simple REST calls
- Team not familiar with reactive
- Low to medium traffic
- CRUD operations

**When to Use WebClient:**
- Spring WebFlux
- High concurrency requirements
- Streaming data
- Need backpressure
- Performance-critical applications

**My Decision:**

"I used Feign Client because:
1. My services use Spring MVC (not WebFlux)
2. Simple CRUD operations
3. Easy to understand and maintain
4. Sufficient for project scale

If I were building a high-traffic system (100k+ requests/sec), I'd use WebClient with Spring WebFlux for better resource utilization."

**Hybrid Approach:**

```java
// Low-frequency calls: Feign
@FeignClient(name = "AUTH-SERVICE")
public interface AuthServiceClient {
    @GetMapping("/api/auth/verify/{userId}")
    UserDTO verifyUser(@PathVariable Long userId);
}

// High-frequency calls: WebClient
@Service
public class JobSearchService {
    
    @Autowired
    private WebClient webClient;
    
    public Flux<JobDTO> searchJobs(String keyword) {
        return webClient
            .get()
            .uri("/api/jobs/search?keyword={keyword}", keyword)
            .retrieve()
            .bodyToFlux(JobDTO.class);
    }
}
```

---

### Q21: Event-Driven Architecture and Kafka Integration

**Your Answer:**

"Event-driven architecture is where services communicate through events rather than direct calls.

**Event-Driven vs Request-Driven:**

**Request-Driven (Traditional):**
```
Job Service: "Hey Notification Service, send email to user@example.com"
Notification Service: "Ok, done"
Job Service: "Thanks, now I can continue"
```

**Event-Driven:**
```
Job Service: "Job posted!" (publishes event to message broker)
                    ‚Üì
            Message Broker
                    ‚Üì
Multiple Consumers:
- Notification Service: Sends email
- Analytics Service: Updates stats
- Search Service: Indexes job
```

**My Implementation (RabbitMQ):**

```java
// Publisher (Job Service)
@Autowired
private RabbitTemplate rabbitTemplate;

public void createJob(Job job) {
    jobRepository.save(job);
    
    JobPostedEvent event = JobPostedEvent.builder()
        .jobId(job.getId())
        .title(job.getTitle())
        .category(job.getCategory())
        .subscribedUsers(getSubscribedUsers(job.getCategory()))
        .build();
    
    rabbitTemplate.convertAndSend("job.exchange", "job.posted", event);
}

// Consumer (Notification Service)
@RabbitListener(queues = "job.posted.queue")
public void handleJobPosted(JobPostedEvent event) {
    event.getSubscribedUsers().forEach(user -> {
        emailService.send(user.getEmail(), "New Job: " + event.getTitle());
    });
}
```

**Apache Kafka (Alternative):**

**When to Use Kafka vs RabbitMQ:**

| Feature | RabbitMQ | Kafka |
|---------|----------|-------|
| Message Model | Queue-based | Log-based |
| Throughput | Good (20k msg/sec) | Excellent (1M+ msg/sec) |
| Message Retention | Until consumed | Configurable (days/weeks) |
| Use Case | Task queues | Event streaming |
| Ordering | Per queue | Per partition |
| Replay | ‚ùå | ‚úÖ |
| Complexity | Simple | Moderate |

**Kafka Implementation:**

```java
// Add dependency
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>

// Configuration
spring:
  kafka:
    bootstrap-servers: localhost:9092
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
    consumer:
      group-id: notification-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer

// Publisher
@Autowired
private KafkaTemplate<String, JobPostedEvent> kafkaTemplate;

public void createJob(Job job) {
    jobRepository.save(job);
    
    JobPostedEvent event = new JobPostedEvent(job);
    kafkaTemplate.send("job-posted-topic", event);
}

// Consumer
@KafkaListener(topics = "job-posted-topic", groupId = "notification-group")
public void handleJobPosted(JobPostedEvent event) {
    sendNotifications(event);
}
```

**Event Sourcing Pattern:**

```
Instead of storing current state:
Job { id: 1, title: "Java Developer", status: "ACTIVE" }

Store sequence of events:
1. JobCreated { id: 1, title: "Java Developer" }
2. JobUpdated { id: 1, title: "Senior Java Developer" }
3. JobActivated { id: 1 }

Current state = replay all events
```

**Benefits of Event-Driven:**
- **Loose Coupling:** Services don't know about each other
- **Scalability:** Add consumers without changing producers
- **Resilience:** Messages persist if consumer is down
- **Audit Trail:** All events logged
- **Replay:** Can replay events to rebuild state

**When to Use Kafka:**
- High throughput (millions of events/sec)
- Need to replay events
- Event sourcing
- Real-time analytics
- Log aggregation

**When to Use RabbitMQ:**
- Task queues
- Request-response patterns
- Priority queues
- Lower throughput
- Simpler operations

**My Choice:**

"I used RabbitMQ because:
1. Sufficient for notification use case
2. Simpler setup and operations
3. Good Spring integration
4. Task queue pattern fits well

For a system with real-time analytics, user activity tracking, or audit logging, I'd use Kafka for its replay capability and high throughput."

---

### Q22: Database Per Service vs Shared Database

**Your Answer:**

**Database Per Service (What I Used):**

**Structure:**
```
Auth Service ‚Üí authdb (users, user_preferences)
Job Service ‚Üí jobdb (jobs, applications)
Notification Service ‚Üí No database (stateless)
```

**Pros:**
‚úÖ **Independence:** Each service can change schema without affecting others
‚úÖ **Technology Flexibility:** Auth Service can use PostgreSQL, Job Service can use MongoDB
‚úÖ **Scalability:** Scale databases independently
‚úÖ **Failure Isolation:** Auth DB crash doesn't affect Job Service
‚úÖ **Team Autonomy:** Teams manage their own databases
‚úÖ **Clear Boundaries:** Forces good service design

**Cons:**
‚ùå **Data Duplication:** May need to store userId in multiple places
‚ùå **No ACID Transactions:** Can't use database transactions across services
‚ùå **Complex Queries:** Can't JOIN across services
‚ùå **Eventual Consistency:** Data may be temporarily out of sync
‚ùå **More Infrastructure:** Multiple databases to manage

**Shared Database (Anti-Pattern):**

**Structure:**
```
Auth Service ‚îÄ‚îÄ‚îê
Job Service ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚Üí shared_database (all tables)
Notification ‚îÄ‚îÄ‚îò
```

**Pros:**
‚úÖ Easy to implement
‚úÖ ACID transactions
‚úÖ Simple queries with JOINs
‚úÖ Less infrastructure

**Cons:**
‚ùå **Tight Coupling:** Schema changes affect all services
‚ùå **No Independence:** Can't deploy services separately
‚ùå **Scaling Issues:** One bottleneck database
‚ùå **Conflicts:** Teams compete for schema changes
‚ùå **Not True Microservices:** Defeats the purpose

**Handling Cross-Service Data:**

**Problem:** Job Service needs user email from Auth Service

**Solution 1: API Calls (Synchronous)**
```java
// Job Service calls Auth Service
@FeignClient(name = "AUTH-SERVICE")
public interface AuthServiceClient {
    @GetMapping("/api/auth/users/{userId}")
    UserDTO getUser(@PathVariable Long userId);
}

public JobResponse createJob(JobRequest request) {
    UserDTO user = authServiceClient.getUser(currentUserId);
    Job job = Job.builder()
        .title(request.getTitle())
        .postedBy(user.getId())
        .postedByEmail(user.getEmail()) // Cache email
        .build();
    return jobRepository.save(job);
}
```

**Solution 2: Events (Asynchronous)**
```java
// Auth Service publishes UserUpdated event
// Job Service listens and updates its local cache

@RabbitListener(queues = "user.updated.queue")
public void handleUserUpdated(UserUpdatedEvent event) {
    // Update local user cache
    userCacheRepository.save(event);
}
```

**Solution 3: Data Denormalization**
```java
// Store necessary data locally
Job {
    id: 1
    title: "Java Developer"
    postedBy: 123 (userId)
    postedByEmail: "hr@company.com" // Denormalized
    postedByName: "HR Manager"      // Denormalized
}
```

**Comparison:**

| Aspect | Database Per Service | Shared Database |
|--------|---------------------|-----------------|
| Independence | High | Low |
| Scalability | High | Low |
| Complexity | High | Low |
| ACID Transactions | No | Yes |
| Team Autonomy | High | Low |
| True Microservices | Yes | No |

**When to Use Shared Database:**
- Monolith to microservices migration (temporarily)
- Very small applications
- Tight ACID requirements
- Team very small (< 5 people)

**When to Use Database Per Service:**
- True microservices architecture
- Large teams
- Different scaling needs
- Long-term maintainability

**My Implementation:**

"I used database per service to demonstrate proper microservices patterns. Each service owns its data and exposes it via APIs. For cross-service data needs, I use Feign Client for synchronous calls and events for updates."

---

### Q23: Saga Pattern for Distributed Transactions

**Your Answer:**

"Saga pattern manages distributed transactions across multiple microservices without using distributed 2-phase commit.

**Problem:**

```
User books a trip (requires 3 services):
1. Payment Service: Charge $500
2. Hotel Service: Reserve room
3. Flight Service: Book ticket

Traditional ACID: All succeed or all fail (database transaction)
Microservices: Each service has its own database ‚Üí Can't use single transaction
```

**What if:**
```
Payment succeeds ‚úÖ
Hotel succeeds ‚úÖ
Flight fails ‚ùå

Money charged but no trip! üò±
```

**Saga Pattern Solution:**

**Two Types:**

**1. Choreography (Event-Based):**

Each service publishes events, next service listens

```
Payment Service:
  - Charge $500
  - Publish: PaymentCompleted
            ‚Üì
Hotel Service (listens to PaymentCompleted):
  - Reserve room
  - Publish: HotelReserved
            ‚Üì
Flight Service (listens to HotelReserved):
  - Book ticket
  - Publish: FlightBooked
  
If Flight fails:
  - Publish: FlightFailed
            ‚Üì
Hotel Service (listens to FlightFailed):
  - Cancel reservation
  - Publish: HotelCancelled
            ‚Üì
Payment Service (listens to HotelCancelled):
  - Refund $500
  - Publish: PaymentRefunded
```

**Implementation:**

```java
// Payment Service
public class PaymentService {
    
    @Transactional
    public void processPayment(Order order) {
        Payment payment = paymentRepository.save(new Payment(order));
        
        PaymentCompletedEvent event = new PaymentCompletedEvent(order.getId(), payment.getId());
        rabbitTemplate.send("payment.completed", event);
    }
    
    @RabbitListener(queues = "payment.refund.queue")
    public void handleRefund(RefundRequestEvent event) {
        Payment payment = paymentRepository.findByOrderId(event.getOrderId());
        payment.refund();
        paymentRepository.save(payment);
    }
}

// Hotel Service
@RabbitListener(queues = "payment.completed.queue")
public void handlePaymentCompleted(PaymentCompletedEvent event) {
    try {
        Reservation reservation = hotelRepository.reserve(event.getOrderId());
        rabbitTemplate.send("hotel.reserved", new HotelReservedEvent(event.getOrderId()));
    } catch (Exception e) {
        // Trigger compensating transaction
        rabbitTemplate.send("payment.refund", new RefundRequestEvent(event.getOrderId()));
    }
}
```

**2. Orchestration (Coordinator-Based):**

Central orchestrator controls the saga

```
                Saga Orchestrator
                       ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì              ‚Üì               ‚Üì
  Payment Service  Hotel Service  Flight Service
  
Orchestrator decides:
1. Call Payment
2. If success, call Hotel
3. If success, call Flight
4. If any fails, trigger compensations
```

**Implementation:**

```java
@Service
public class TripBookingSaga {
    
    @Autowired
    private PaymentServiceClient paymentClient;
    @Autowired
    private HotelServiceClient hotelClient;
    @Autowired
    private FlightServiceClient flightClient;
    
    public void bookTrip(TripBookingRequest request) {
        String paymentId = null;
        String hotelId = null;
        
        try {
            // Step 1: Payment
            paymentId = paymentClient.charge(request.getAmount());
            
            // Step 2: Hotel
            hotelId = hotelClient.reserve(request.getHotelDetails());
            
            // Step 3: Flight
            String flightId = flightClient.book(request.getFlightDetails());
            
            // All success
            sagaRepository.save(new Saga(COMPLETED, paymentId, hotelId, flightId));
            
        } catch (Exception e) {
            // Compensate (rollback)
            if (hotelId != null) {
                hotelClient.cancel(hotelId);
            }
            if (paymentId != null) {
                paymentClient.refund(paymentId);
            }
            
            sagaRepository.save(new Saga(FAILED, paymentId, hotelId, null));
            throw new SagaFailedException("Trip booking failed", e);
        }
    }
}
```

**Comparison:**

| Aspect | Choreography | Orchestration |
|--------|--------------|---------------|
| Coordination | Decentralized | Centralized |
| Complexity | Higher | Lower |
| Coupling | Loose | Tighter |
| Debugging | Harder | Easier |
| Use Case | Simple flows | Complex flows |

**In My Project:**

"I don't have distributed transactions currently, but if I added a payment feature:

```
Apply for Job Saga:
1. Job Service: Create application
2. Payment Service: Charge application fee
3. Notification Service: Send confirmation

If payment fails:
- Delete application
- Notify user of failure
```

I'd use Orchestration pattern because:
- Only 2-3 services involved
- Clear business flow
- Easier to debug
- Centralized error handling"

**Key Considerations:**
- Each step must be idempotent (can be retried safely)
- Compensating transactions must be defined
- Timeouts and retries needed
- Saga state must be persisted
- Eventual consistency accepted

---

### Q24: JWT Authentication and OAuth2 in Microservices

**Your Answer:**

**JWT Authentication (What I Implemented):**

**Flow:**
```
1. User logs in ‚Üí Auth Service
2. Auth Service validates credentials
3. Auth Service generates JWT token
4. User stores token
5. User sends token with each request
6. Each service validates token independently
```

**JWT Structure:**
```
eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJqb2huIn0.signature

Header:
{
  "alg": "HS256",
  "typ": "JWT"
}

Payload:
{
  "sub": "john_doe",
  "userId": 123,
  "role": "USER",
  "iat": 1234567890,
  "exp": 1234657890
}

Signature:
HMACSHA256(header + payload, secret_key)
```

**Implementation:**

```java
// Generate Token
public String generateToken(UserDetails userDetails) {
    Map<String, Object> claims = new HashMap<>();
    claims.put("userId", user.getId());
    claims.put("role", user.getRole());
    
    return Jwts.builder()
        .setClaims(claims)
        .setSubject(userDetails.getUsername())
        .setIssuedAt(new Date())
        .setExpiration(new Date(System.currentTimeMillis() + 86400000))
        .signWith(getSigningKey(), SignatureAlgorithm.HS256)
        .compact();
}

// Validate Token
public Boolean validateToken(String token) {
    try {
        Jwts.parserBuilder()
            .setSigningKey(getSigningKey())
            .build()
            .parseClaimsJws(token);
        return !isTokenExpired(token);
    } catch (JwtException e) {
        return false;
    }
}

// Extract Claims
public String extractUsername(String token) {
    return extractClaim(token, Claims::getSubject);
}

public String extractRole(String token) {
    return extractClaim(token, claims -> claims.get("role", String.class));
}
```

**JWT in Microservices:**

```
Client Request:
GET /api/jobs
Header: Authorization: Bearer eyJhbGciOiJIUzI1NiJ9...

API Gateway:
- Extracts token
- Validates signature
- Forwards to Job Service with user info

Job Service:
- Receives request with validated token
- Extracts userId and role
- Processes request
```

**OAuth2 (Industry Standard):**

**What is OAuth2:**
"OAuth2 is an authorization framework that allows third-party applications to access user data without sharing passwords."

**Use Cases:**
- "Login with Google"
- "Login with GitHub"
- "Login with Facebook"

**OAuth2 Flow (Authorization Code):**

```
1. User clicks "Login with Google"
2. Redirect to Google Login
3. User logs in to Google
4. Google redirects back with authorization code
5. Your app exchanges code for access token
6. Your app uses access token to get user info from Google
7. Your app creates session/JWT for user
```

**Implementation with Spring Security:**

```java
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-oauth2-client</artifactId>
</dependency>

// application.yml
spring:
  security:
    oauth2:
      client:
        registration:
          google:
            client-id: ${GOOGLE_CLIENT_ID}
            client-secret: ${GOOGLE_CLIENT_SECRET}
            scope: profile, email
          github:
            client-id: ${GITHUB_CLIENT_ID}
            client-secret: ${GITHUB_CLIENT_SECRET}
            scope: user:email

// Security Configuration
@Configuration
public class SecurityConfig {
    
    @Bean
    public SecurityFilterChain filterChain(HttpSecurity http) throws Exception {
        http
            .oauth2Login()
                .userInfoEndpoint()
                    .userService(customOAuth2UserService())
                .and()
            .and()
            .authorizeHttpRequests()
                .anyRequest().authenticated();
        return http.build();
    }
}

// Custom User Service
@Service
public class CustomOAuth2UserService extends DefaultOAuth2UserService {
    
    @Override
    public OAuth2User loadUser(OAuth2UserRequest userRequest) {
        OAuth2User oauth2User = super.loadUser(userRequest);
        
        // Extract user info
        String email = oauth2User.getAttribute("email");
        String name = oauth2User.getAttribute("name");
        
        // Create or update user in your database
        User user = userRepository.findByEmail(email)
            .orElseGet(() -> createUser(email, name));
        
        // Generate JWT for your system
        String jwtToken = jwtUtil.generateToken(user);
        
        return oauth2User;
    }
}
```

**OAuth2 + JWT Hybrid:**

```
1. User logs in with Google OAuth2
2. Your Auth Service receives OAuth2 token
3. Auth Service validates with Google
4. Auth Service creates JWT for internal use
5. Client uses JWT for subsequent requests
6. Microservices validate JWT (no Google involved)
```

**Comparison:**

| Aspect | JWT Only | OAuth2 |
|--------|----------|--------|
| Use Case | Internal auth | Third-party login |
| Complexity | Simple | Moderate |
| User Management | You manage | Provider manages |
| Token Type | JWT | OAuth2 tokens + JWT |
| Best For | Internal systems | Consumer apps |

**My Implementation:**

"I used JWT-only authentication because:
1. Simple internal authentication needed
2. Don't need third-party login
3. Complete control over user management
4. Easier to implement and understand

For a production job board accessible to public, I'd add OAuth2 to allow:
- Login with Google
- Login with LinkedIn
- Login with GitHub

This improves user experience (no password to remember) and reduces registration friction."

**Security Best Practices:**
```java
// 1. Use strong secret (256-bit)
jwt.secret=${JWT_SECRET}  // From environment variable

// 2. Short expiration
jwt.expiration=900000  // 15 minutes

// 3. Implement refresh tokens
jwt.refresh-expiration=604800000  // 7 days

// 4. Store tokens securely (HttpOnly cookies)
Cookie cookie = new Cookie("token", jwtToken);
cookie.setHttpOnly(true);
cookie.setSecure(true);  // HTTPS only
cookie.setPath("/");

// 5. Token blacklist for logout
@Service
public class TokenBlacklistService {
    private Set<String> blacklist = new HashSet<>();
    
    public void blacklistToken(String token) {
        blacklist.add(token);
    }
    
    public boolean isBlacklisted(String token) {
        return blacklist.contains(token);
    }
}
```

---

### Q25: Security in API Gateway

**Your Answer:**

"API Gateway is the entry point, so it's critical for security.

**Security Layers I'd Implement:**

**1. JWT Validation at Gateway:**

```java
@Component
public class JwtAuthenticationFilter implements GlobalFilter {
    
    @Autowired
    private JwtUtil jwtUtil;
    
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ServerHttpRequest request = exchange.getRequest();
        
        // Skip auth for public endpoints
        if (isPublicEndpoint(request.getPath().value())) {
            return chain.filter(exchange);
        }
        
        // Extract token
        String token = extractToken(request);
        if (token == null || !jwtUtil.validateToken(token)) {
            exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);
            return exchange.getResponse().setComplete();
        }
        
        // Add user info to headers for downstream services
        String userId = jwtUtil.extractUserId(token);
        String role = jwtUtil.extractRole(token);
        
        ServerHttpRequest mutatedRequest = request.mutate()
            .header("X-User-Id", userId)
            .header("X-User-Role", role)
            .build();
        
        return chain.filter(exchange.mutate().request(mutatedRequest).build());
    }
    
    private boolean isPublicEndpoint(String path) {
        return path.startsWith("/api/auth/register") ||
               path.startsWith("/api/auth/login") ||
               path.startsWith("/api/jobs") && request.getMethod().equals("GET");
    }
}
```

**2. Rate Limiting:**

```java
// Prevent abuse and DDoS
@Bean
public RouteLocator routes(RouteLocatorBuilder builder) {
    return builder.routes()
        .route("rate_limited_route", r -> r
            .path("/api/**")
            .filters(f -> f
                .requestRateLimiter(config -> config
                    .setRateLimiter(redisRateLimiter())
                    .setKeyResolver(userKeyResolver())))
            .uri("lb://JOB-SERVICE"))
        .build();
}

@Bean
public RedisRateLimiter redisRateLimiter() {
    return new RedisRateLimiter(10, 20); // 10 requests per second, burst 20
}

@Bean
public KeyResolver userKeyResolver() {
    return exchange -> {
        String userId = exchange.getRequest().getHeaders().getFirst("X-User-Id");
        return Mono.just(userId != null ? userId : exchange.getRequest().getRemoteAddress().toString());
    };
}
```

**3. CORS Configuration:**

```yaml
spring:
  cloud:
    gateway:
      globalcors:
        corsConfigurations:
          '[/**]':
            allowedOrigins: 
              - "https://yourfrontend.com"
            allowedMethods:
              - GET
              - POST
              - PUT
              - DELETE
            allowedHeaders: "*"
            allowCredentials: true
            maxAge: 3600
```

**4. Request/Response Sanitization:**

```java
@Component
public class SanitizationFilter implements GlobalFilter {
    
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ServerHttpRequest request = exchange.getRequest();
        
        // Remove sensitive headers
        ServerHttpRequest sanitized = request.mutate()
            .headers(headers -> {
                headers.remove("X-Internal-Secret");
                headers.remove("X-Database-Password");
            })
            .build();
        
        return chain.filter(exchange.mutate().request(sanitized).build());
    }
}
```

**5. IP Whitelisting (for admin endpoints):**

```java
@Bean
public RouteLocator adminRoutes(RouteLocatorBuilder builder) {
    return builder.routes()
        .route("admin_route", r -> r
            .path("/admin/**")
            .and()
            .remoteAddr("192.168.1.0/24") // Only allow from this IP range
            .uri("lb://ADMIN-SERVICE"))
        .build();
}
```

**6. SSL/TLS Enforcement:**

```yaml
server:
  ssl:
    enabled: true
    key-store: classpath:keystore.p12
    key-store-password: ${KEYSTORE_PASSWORD}
    key-store-type: PKCS12
  
# Redirect HTTP to HTTPS
spring:
  cloud:
    gateway:
      httpclient:
        ssl:
          useInsecureTrustManager: false
```

**7. Request Size Limits:**

```yaml
spring:
  codec:
    max-in-memory-size: 10MB  # Prevent large payload attacks
```

**8. Circuit Breaker for Security:**

```java
@Bean
public RouteLocator secureRoutes(RouteLocatorBuilder builder) {
    return builder.routes()
        .route("protected_route", r -> r
            .path("/api/jobs/**")
            .filters(f -> f
                .circuitBreaker(config -> config
                    .setName("jobServiceCB")
                    .setFallbackUri("forward:/fallback")))
            .uri("lb://JOB-SERVICE"))
        .build();
}
```

**9. Audit Logging:**

```java
@Component
public class AuditLogFilter implements GlobalFilter {
    
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ServerHttpRequest request = exchange.getRequest();
        
        String userId = request.getHeaders().getFirst("X-User-Id");
        String path = request.getPath().value();
        String method = request.getMethod().toString();
        
        log.info("Request: user={}, method={}, path={}, ip={}", 
            userId, method, path, request.getRemoteAddress());
        
        return chain.filter(exchange).then(Mono.fromRunnable(() -> {
            log.info("Response: user={}, status={}", 
                userId, exchange.getResponse().getStatusCode());
        }));
    }
}
```

**10. API Key Authentication (for B2B):**

```java
@Component
public class ApiKeyFilter implements GlobalFilter {
    
    private static final String API_KEY_HEADER = "X-API-Key";
    
    @Override
    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ServerHttpRequest request = exchange.getRequest();
        
        if (request.getPath().value().startsWith("/api/public")) {
            String apiKey = request.getHeaders().getFirst(API_KEY_HEADER);
            
            if (apiKey == null || !isValidApiKey(apiKey)) {
                exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);
                return exchange.getResponse().setComplete();
            }
        }
        
        return chain.filter(exchange);
    }
    
    private boolean isValidApiKey(String apiKey) {
        // Check against database or cache
        return apiKeyRepository.existsByKey(apiKey);
    }
}
```

**Security Checklist:**
- ‚úÖ JWT validation at gateway
- ‚úÖ Rate limiting per user/IP
- ‚úÖ CORS properly configured
- ‚úÖ HTTPS/TLS enforced
- ‚úÖ Request size limits
- ‚úÖ IP whitelisting for admin
- ‚úÖ Audit logging
- ‚úÖ Circuit breaker for resilience
- ‚úÖ Input sanitization
- ‚úÖ API key for B2B

---

### Q26: Observability - Logging, Tracing, and Monitoring

**Your Answer:**

"Observability is critical in microservices because failures can happen in any service.

**Three Pillars of Observability:**

**1. Logging (What happened?):**

**Centralized Logging with ELK Stack:**

```
Microservices ‚Üí Logstash ‚Üí Elasticsearch ‚Üí Kibana (Visualization)
```

**Implementation:**

```xml
<!-- Add Logstash encoder -->
<dependency>
    <groupId>net.logstash.logback</groupId>
    <artifactId>logstash-logback-encoder</artifactId>
</dependency>
```

```xml
<!-- logback-spring.xml -->
<configuration>
    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>logstash:5000</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <customFields>{"service":"job-service"}</customFields>
        </encoder>
    </appender>
    
    <root level="INFO">
        <appender-ref ref="LOGSTASH" />
    </root>
</configuration>
```

**Structured Logging:**

```java
@Slf4j
@Service
public class JobService {
    
    public Job createJob(JobRequest request) {
        MDC.put("userId", SecurityContextHolder.getContext().getAuthentication().getName());
        MDC.put("jobId", UUID.randomUUID().toString());
        
        log.info("Creating job: title={}, company={}", request.getTitle(), request.getCompany());
        
        try {
            Job job = jobRepository.save(new Job(request));
            log.info("Job created successfully: jobId={}", job.getId());
            return job;
        } catch (Exception e) {
            log.error("Failed to create job", e);
            throw e;
        } finally {
            MDC.clear();
        }
    }
}
```

**2. Tracing (Where did it go?):**

**Distributed Tracing with Zipkin:**

```
Request ‚Üí API Gateway ‚Üí Job Service ‚Üí Auth Service
   |            |              |              |
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚Üí Zipkin
```

**Implementation:**

```xml
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-tracing-bridge-brave</artifactId>
</dependency>
<dependency>
    <groupId>io.zipkin.reporter2</groupId>
    <artifactId>zipkin-reporter-brave</artifactId>
</dependency>
```

```yaml
# application.yml
management:
  tracing:
    sampling:
      probability: 1.0  # 100% sampling (use 0.1 for 10% in prod)
  zipkin:
    tracing:
      endpoint: http://zipkin:9411/api/v2/spans
```

**Trace ID Propagation:**

```
Request comes in with Trace-ID: abc123

API Gateway (Trace-ID: abc123)
    ‚Üì
Job Service (Trace-ID: abc123, Span-ID: def456)
    ‚Üì
Auth Service (Trace-ID: abc123, Span-ID: ghi789)

All logs tagged with same Trace-ID
Can see full request path in Zipkin UI
```

**3. Monitoring (How is it performing?):**

**Metrics with Prometheus + Grafana:**

```
Services expose metrics ‚Üí Prometheus scrapes ‚Üí Grafana visualizes
```

**Implementation:**

```xml
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
```

**Custom Metrics:**

```java
@Service
public class JobService {
    
    private final Counter jobCreatedCounter;
    private final Timer jobCreationTimer;
    
    public JobService(MeterRegistry registry) {
        this.jobCreatedCounter = Counter.builder("jobs.created")
            .description("Total jobs created")
            .tag("service", "job-service")
            .register(registry);
        
        this.jobCreationTimer = Timer.builder("jobs.creation.time")
            .description("Time to create job")
            .register(registry);
    }
    
    public Job createJob(JobRequest request) {
        return jobCreationTimer.record(() -> {
            Job job = jobRepository.save(new Job(request));
            jobCreatedCounter.increment();
            return job;
        });
    }
}
```

**Prometheus Configuration:**

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'spring-actuator'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['job-service:8082', 'auth-service:8081']
```

**Grafana Dashboard Metrics:**
- Request rate (requests/sec)
- Error rate (%)
- Response time (p50, p95, p99)
- CPU/Memory usage
- Database connection pool
- JVM metrics (heap, GC)
- Custom business metrics (jobs created, applications submitted)

**Alerting:**

```yaml
# Alert rules in Prometheus
groups:
  - name: service_alerts
    rules:
      - alert: HighErrorRate
        expr: rate(http_server_requests_seconds_count{status="500"}[5m]) > 0.05
        annotations:
          summary: "High error rate detected"
      
      - alert: SlowResponseTime
        expr: http_server_requests_seconds{quantile="0.95"} > 1
        annotations:
          summary: "95th percentile response time > 1s"
      
      - alert: ServiceDown
        expr: up == 0
        for: 2m
        annotations:
          summary: "Service {{ $labels.job }} is down"
```

**Health Checks:**

```java
@Component
public class CustomHealthIndicator implements HealthIndicator {
    
    @Autowired
    private DataSource dataSource;
    
    @Autowired
    private RabbitTemplate rabbitTemplate;
    
    @Override
    public Health health() {
        try {
            // Check database
            dataSource.getConnection().isValid(1);
            
            // Check RabbitMQ
            rabbitTemplate.getConnectionFactory().createConnection().isOpen();
            
            return Health.up()
                .withDetail("database", "UP")
                .withDetail("rabbitmq", "UP")
                .build();
        } catch (Exception e) {
            return Health.down()
                .withDetail("error", e.getMessage())
                .build();
        }
    }
}
```

**Observability Best Practices:**

1. **Use Correlation IDs:** Track requests across services
2. **Structured Logs:** JSON format for easy parsing
3. **Log Levels:** INFO for normal, WARN for potential issues, ERROR for failures
4. **Don't Log Sensitive Data:** No passwords, tokens, PII
5. **Sample Traces:** 10% sampling in production (reduce overhead)
6. **Set SLOs:** Response time < 200ms for 95% requests
7. **Dashboard for Each Service:** Quick health overview
8. **Alert on Anomalies:** Not just thresholds

**My Current Setup:**

"Currently using Spring Boot Actuator for health checks. In production, I'd add:
- ELK stack for centralized logging
- Zipkin for distributed tracing
- Prometheus + Grafana for monitoring
- PagerDuty for alerting

This gives complete visibility into the system."

---

### Q27: Prometheus and Grafana in Microservices

**Your Answer:**

"Prometheus and Grafana work together for monitoring and visualization.

**Prometheus (Metrics Collection):**

**What it does:**
- Scrapes metrics from services
- Stores time-series data
- Evaluates alerting rules
- Provides query language (PromQL)

**Architecture:**

```
Job Service:8082/actuator/prometheus
Auth Service:8081/actuator/prometheus
            ‚Üì
Prometheus (scrapes every 15s)
            ‚Üì
Stores metrics in time-series DB
            ‚Üì
Grafana queries Prometheus
            ‚Üì
Visualizes on dashboard
```

**Setup:**

**1. Enable Prometheus in Spring Boot:**

```xml
<dependency>
    <groupId>io.micrometer</groupId>
    <artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```

```yaml
management:
  endpoints:
    web:
      exposure:
        include: prometheus,health,info,metrics
  metrics:
    export:
      prometheus:
        enabled: true
```

**2. Prometheus Configuration:**

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'api-gateway'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['api-gateway:8080']
  
  - job_name: 'auth-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['auth-service:8081']
  
  - job_name: 'job-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['job-service:8082']
  
  - job_name: 'notification-service'
    metrics_path: '/actuator/prometheus'
    static_configs:
      - targets: ['notification-service:8083']
```

**3. Docker Compose:**

```yaml
services:
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
  
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - prometheus
```

**Key Metrics to Monitor:**

**Application Metrics:**
```
http_server_requests_seconds_count  # Request count
http_server_requests_seconds_sum    # Total time
http_server_requests_seconds_max    # Max response time
```

**JVM Metrics:**
```
jvm_memory_used_bytes               # Memory usage
jvm_gc_pause_seconds_count          # GC count
jvm_threads_live_threads            # Active threads
```

**Database Metrics:**
```
hikaricp_connections_active         # Active DB connections
hikaricp_connections_idle           # Idle connections
hikaricp_connections_pending        # Pending requests
```

**Custom Metrics:**
```
jobs_created_total                  # Jobs posted
applications_submitted_total        # Applications submitted
emails_sent_total                   # Notifications sent
```

**Grafana (Visualization):**

**Setup Dashboard:**

1. **Add Prometheus as Data Source:**
```
Configuration ‚Üí Data Sources ‚Üí Add Prometheus
URL: http://prometheus:9090
```

2. **Import Dashboard:**
```
Create ‚Üí Import ‚Üí Dashboard ID: 11378 (JVM Micrometer)
```

3. **Custom Dashboard Panels:**

**Panel 1: Request Rate**
```promql
rate(http_server_requests_seconds_count[5m])
```

**Panel 2: Error Rate**
```promql
rate(http_server_requests_seconds_count{status="500"}[5m]) /
rate(http_server_requests_seconds_count[5m]) * 100
```

**Panel 3: Response Time (95th percentile)**
```promql
histogram_quantile(0.95, 
  rate(http_server_requests_seconds_bucket[5m])
)
```

**Panel 4: Active Jobs**
```promql
jobs_created_total - jobs_deleted_total
```

**Panel 5: Database Connections**
```promql
hikaricp_connections_active{application="job-service"}
```

**Panel 6: Memory Usage**
```promql
jvm_memory_used_bytes{area="heap"} / 
jvm_memory_max_bytes{area="heap"} * 100
```

**Alerting in Grafana:**

```json
{
  "alert": "High Error Rate",
  "expr": "rate(http_server_requests_seconds_count{status=\"500\"}[5m]) > 0.05",
  "for": "5m",
  "annotations": {
    "summary": "Error rate above 5% for 5 minutes",
    "description": "Service {{ $labels.application }} has error rate of {{ $value }}%"
  },
  "actions": [
    {
      "type": "email",
      "to": "oncall@company.com"
    },
    {
      "type": "slack",
      "channel": "#alerts"
    }
  ]
}
```

**Sample Dashboard Layout:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Job Board - Overview                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Request Rate    ‚îÇ   Error Rate     ‚îÇ  Response Time‚îÇ
‚îÇ  1.2k req/s      ‚îÇ   0.5%           ‚îÇ  45ms (p95)   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                      ‚îÇ
‚îÇ  [Request Rate Graph - Last 6 hours]                ‚îÇ
‚îÇ                                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                      ‚îÇ
‚îÇ  [Error Rate by Service - Last 6 hours]             ‚îÇ
‚îÇ                                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Memory Usage    ‚îÇ  Database Connections            ‚îÇ
‚îÇ  [Graph]         ‚îÇ  [Graph]                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Service Status                                     ‚îÇ
‚îÇ  ‚óè API Gateway: UP    ‚óè Auth Service: UP           ‚îÇ
‚îÇ  ‚óè Job Service: UP    ‚óè Notification: UP           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Benefits:**
- Real-time monitoring
- Historical data analysis
- Quick issue identification
- Performance optimization
- Capacity planning

**My Implementation:**

"I'd set up Prometheus + Grafana to monitor:
- API response times per endpoint
- Error rates by service
- RabbitMQ queue depth
- Database connection pool
- JVM memory and GC

This helps identify bottlenecks and predict when to scale."

---

### Q28: Kubernetes Deployment for Microservices

**Your Answer:**

"Kubernetes orchestrates containerized applications across a cluster.

**Why Kubernetes for Microservices:**
- **Auto-scaling:** Scale pods based on CPU/memory
- **Self-healing:** Restart failed containers
- **Service Discovery:** Built-in DNS for services
- **Load Balancing:** Distribute traffic across pods
- **Rolling Updates:** Zero-downtime deployments
- **Secret Management:** Secure credential storage

**Basic Kubernetes Objects:**

**1. Deployment (Job Service):**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: job-service
  labels:
    app: job-service
spec:
  replicas: 3  # Run 3 instances
  selector:
    matchLabels:
      app: job-service
  template:
    metadata:
      labels:
        app: job-service
    spec:
      containers:
      - name: job-service
        image: yourusername/job-service:latest
        ports:
        - containerPort: 8082
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: EUREKA_CLIENT_SERVICEURL_DEFAULTZONE
          value: "http://eureka-server:8761/eureka/"
        - name: SPRING_RABBITMQ_HOST
          value: "rabbitmq"
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: jwt-secret
              key: secret
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8082
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8082
          initialDelaySeconds: 20
          periodSeconds: 5
```

**2. Service (Load Balancer):**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: job-service
spec:
  selector:
    app: job-service
  ports:
  - port: 8082
    targetPort: 8082
  type: ClusterIP  # Internal service
```

**3. Ingress (External Access):**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: api-gateway-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: api.jobboard.com
    http:
      paths:
      - path: /api/auth
        pathType: Prefix
        backend:
          service:
            name: auth-service
            port:
              number: 8081
      - path: /api/jobs
        pathType: Prefix
        backend:
          service:
            name: job-service
            port:
              number: 8082
```

**4. ConfigMap (Configuration):**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  application.yml: |
    server:
      port: 8082
    spring:
      application:
        name: job-service
    logging:
      level:
        root: INFO
```

**5. Secret (Sensitive Data):**

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: jwt-secret
type: Opaque
data:
  secret: <base64-encoded-secret>
```

**6. HorizontalPodAutoscaler:**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: job-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: job-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

**Complete Deployment Commands:**

```bash
# 1. Create namespace
kubectl create namespace job-board

# 2. Apply secrets
kubectl apply -f secrets.yaml -n job-board

# 3. Deploy databases (using StatefulSet)
kubectl apply -f postgres-statefulset.yaml -n job-board

# 4. Deploy RabbitMQ
kubectl apply -f rabbitmq-deployment.yaml -n job-board

# 5. Deploy Eureka Server
kubectl apply -f eureka-deployment.yaml -n job-board

# 6. Deploy microservices
kubectl apply -f auth-service-deployment.yaml -n job-board
kubectl apply -f job-service-deployment.yaml -n job-board
kubectl apply -f notification-service-deployment.yaml -n job-board

# 7. Deploy API Gateway
kubectl apply -f api-gateway-deployment.yaml -n job-board

# 8. Create ingress
kubectl apply -f ingress.yaml -n job-board

# 9. Verify deployments
kubectl get pods -n job-board
kubectl get services -n job-board

# 10. Check logs
kubectl logs -f deployment/job-service -n job-board

# 11. Scale deployment
kubectl scale deployment job-service --replicas=5 -n job-board
```

**Helm Chart (Package Manager):**

```yaml
# Chart.yaml
apiVersion: v2
name: job-board
description: Job Board Microservices
version: 1.0.0

# values.yaml
jobService:
  replicaCount: 3
  image:
    repository: yourusername/job-service
    tag: latest
  resources:
    limits:
      memory: 1Gi
      cpu: 1000m
```

```bash
# Install with Helm
helm install job-board ./job-board-chart -n job-board

# Upgrade
helm upgrade job-board ./job-board-chart -n job-board

# Rollback
helm rollback job-board 1
```

**Benefits of Kubernetes:**
- Automated deployment and scaling
- Self-healing (restart failed pods)
- Service discovery and load balancing
- Secret and config management
- Rolling updates with zero downtime
- Resource isolation and limits

---

### Q29: Blue-Green and Canary Deployments

**Your Answer:**

"Blue-Green and Canary are deployment strategies to minimize risk during releases.

**Blue-Green Deployment:**

**Concept:**
```
Blue (Current): v1.0 - 100% traffic
Green (New): v2.0 - 0% traffic

Deploy v2.0 to Green ‚Üí Test ‚Üí Switch traffic ‚Üí Blue becomes standby
```

**Implementation in Kubernetes:**

```yaml
# Blue Deployment (v1.0)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: job-service-blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: job-service
      version: v1
  template:
    metadata:
      labels:
        app: job-service
        version: v1
    spec:
      containers:
      - name: job-service
        image: yourusername/job-service:v1.0

---
# Green Deployment (v2.0)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: job-service-green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: job-service
      version: v2
  template:
    metadata:
      labels:
        app: job-service
        version: v2
    spec:
      containers:
      - name: job-service
        image: yourusername/job-service:v2.0

---
# Service (points to Blue initially)
apiVersion: v1
kind: Service
metadata:
  name: job-service
spec:
  selector:
    app: job-service
    version: v1  # Switch to v2 for Green
  ports:
  - port: 8082
```

**Deployment Process:**

```bash
# 1. Deploy Green (v2.0)
kubectl apply -f job-service-green-deployment.yaml

# 2. Test Green in isolation
kubectl port-forward deployment/job-service-green 9082:8082

# 3. Switch traffic to Green
kubectl patch service job-service -p '{"spec":{"selector":{"version":"v2"}}}'

# 4. Monitor metrics
# If issues: kubectl patch service job-service -p '{"spec":{"selector":{"version":"v1"}}}'

# 5. After confirming success, delete Blue
kubectl delete deployment job-service-blue
```

**Pros:**
‚úÖ Instant rollback (just switch service selector)
‚úÖ Zero downtime
‚úÖ Test in production environment before going live
‚úÖ Simple concept

**Cons:**
‚ùå Need double resources (Blue + Green running)
‚ùå Database migrations complex
‚ùå All or nothing switch

**Canary Deployment:**

**Concept:**
```
v1.0: 90% traffic
v2.0: 10% traffic (canary)

If canary healthy ‚Üí Increase to 50% ‚Üí Then 100%
If canary fails ‚Üí Rollback immediately
```

**Implementation with Kubernetes + Istio:**

```yaml
# v1 Deployment (90% traffic)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: job-service-v1
spec:
  replicas: 9  # 90%
  selector:
    matchLabels:
      app: job-service
      version: v1
  template:
    metadata:
      labels:
        app: job-service
        version: v1
    spec:
      containers:
      - name: job-service
        image: yourusername/job-service:v1.0

---
# v2 Deployment (10% traffic - Canary)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: job-service-v2
spec:
  replicas: 1  # 10%
  selector:
    matchLabels:
      app: job-service
      version: v2
  template:
    metadata:
      labels:
        app: job-service
        version: v2
    spec:
      containers:
      - name: job-service
        image: yourusername/job-service:v2.0

---
# Service (both versions)
apiVersion: v1
kind: Service
metadata:
  name: job-service
spec:
  selector:
    app: job-service  # Matches both v1 and v2
  ports:
  - port: 8082
```

**With Istio for Fine-Grained Control:**

```yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: job-service
spec:
  hosts:
  - job-service
  http:
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: job-service
        subset: v2
  - route:
    - destination:
        host: job-service
        subset: v1
      weight: 90
    - destination:
        host: job-service
        subset: v2
      weight: 10
```

**Canary Deployment Strategy:**

```bash
# Phase 1: Deploy canary (10%)
kubectl apply -f job-service-v2-deployment.yaml
# Monitor metrics for 1 hour

# Phase 2: Increase to 50%
kubectl scale deployment job-service-v1 --replicas=5
kubectl scale deployment job-service-v2 --replicas=5
# Monitor for 2 hours

# Phase 3: Full rollout (100%)
kubectl scale deployment job-service-v1 --replicas=0
kubectl scale deployment job-service-v2 --replicas=10

# If issues at any phase:
kubectl scale deployment job-service-v2 --replicas=0
```

**Automated Canary with Flagger:**

```yaml
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: job-service
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: job-service
  service:
    port: 8082
  analysis:
    interval: 1m
    threshold: 5
    maxWeight: 50
    stepWeight: 10
    metrics:
    - name: request-success-rate
      thresholdRange:
        min: 99
      interval: 1m
    - name: request-duration
      thresholdRange:
        max: 500
      interval: 1m
```

**Monitoring Canary:**

```promql
# Error rate comparison
rate(http_server_requests_seconds_count{version="v2",status="500"}[5m]) vs
rate(http_server_requests_seconds_count{version="v1",status="500"}[5m])

# Response time comparison
histogram_quantile(0.95, rate(http_server_requests_seconds_bucket{version="v2"}[5m])) vs
histogram_quantile(0.95, rate(http_server_requests_seconds_bucket{version="v1"}[5m]))
```

**Comparison:**

| Aspect | Blue-Green | Canary |
|--------|-----------|--------|
| Risk | Low | Very Low |
| Rollback | Instant | Gradual |
| Resource Usage | 2x | 1.1x - 1.5x |
| Complexity | Simple | Moderate |
| Testing | Pre-switch test | Live traffic test |
| Database Migrations | Challenging | Easier |
| Best For | Major releases | Incremental changes |

**My Choice:**

"For my Job Board:

**Blue-Green for:**
- Major version upgrades (v1.0 ‚Üí v2.0)
- Database schema changes
- API contract changes

**Canary for:**
- Bug fixes
- Performance improvements
- Feature flags
- Algorithm changes (search ranking)

I'd use Canary by default as it's safer - you catch issues with 10% traffic before affecting everyone."

---

### Q30: WebFlux for Reactive Microservices

**Your Answer:**

"WebFlux is Spring's reactive web framework for non-blocking, asynchronous applications.

**Traditional Spring MVC (Blocking):**

```java
@RestController
public class JobController {
    
    @GetMapping("/api/jobs/{id}")
    public Job getJob(@PathVariable Long id) {
        // Thread waits here
        Job job = jobRepository.findById(id);
        // Thread waits here
        User user = authServiceClient.getUser(job.getPostedBy());
        // Thread waits here
        return job;
    }
}

Thread-per-request model:
- 1000 concurrent requests = 1000 threads
- Each thread: 1MB stack = 1GB memory
- Context switching overhead
```

**Spring WebFlux (Non-Blocking):**

```java
@RestController
public class JobController {
    
    @GetMapping("/api/jobs/{id}")
    public Mono<Job> getJob(@PathVariable Long id) {
        return jobRepository.findById(id)  // Returns immediately
            .flatMap(job -> 
                authServiceClient.getUser(job.getPostedBy())  // Non-blocking
                    .map(user -> {
                        job.setPostedBy(user);
                        return job;
                    })
            );
    }
}

Event-loop model:
- 1000 concurrent requests = 8 threads (CPU cores)
- Threads never block
- Better resource utilization
```

**Key Reactive Types:**

**Mono (0 or 1 element):**
```java
Mono<Job> job = jobRepository.findById(id);
Mono<User> user = authServiceClient.getUser(userId);
```

**Flux (0 to N elements):**
```java
Flux<Job> jobs = jobRepository.findAll();
Flux<Application> applications = applicationRepository.findByUserId(userId);
```

**Reactive Repository:**

```java
public interface JobRepository extends ReactiveMongoRepository<Job, String> {
    
    Flux<Job> findByCategory(String category);
    
    Mono<Job> findByTitle(String title);
    
    @Query("{ 'postedBy': ?0 }")
    Flux<Job> findByPostedBy(Long userId);
}
```

**Reactive Service:**

```java
@Service
public class JobService {
    
    @Autowired
    private JobRepository jobRepository;
    
    @Autowired
    private WebClient authServiceClient;
    
    public Mono<JobResponse> createJob(JobRequest request) {
        return authServiceClient
            .get()
            .uri("/api/auth/me")
            .retrieve()
            .bodyToMono(UserDTO.class)
            .flatMap(user -> {
                Job job = Job.builder()
                    .title(request.getTitle())
                    .postedBy(user.getId())
                    .build();
                return jobRepository.save(job);
            })
            .map(this::toResponse);
    }
    
    public Flux<JobResponse> searchJobs(String keyword) {
        return jobRepository.findAll()
            .filter(job -> job.getTitle().contains(keyword))
            .map(this::toResponse);
    }
    
    // Combine multiple async calls
    public Mono<JobDetailResponse> getJobWithApplications(Long jobId) {
        Mono<Job> jobMono = jobRepository.findById(jobId);
        Flux<Application> appFlux = applicationRepository.findByJobId(jobId);
        
        return jobMono.zipWith(appFlux.collectList())
            .map(tuple -> {
                Job job = tuple.getT1();
                List<Application> applications = tuple.getT2();
                return new JobDetailResponse(job, applications);
            });
    }
}
```

**Reactive Controller:**

```java
@RestController
@RequestMapping("/api/jobs")
public class JobController {
    
    @Autowired
    private JobService jobService;
    
    @GetMapping(produces = MediaType.APPLICATION_NDJSON_VALUE)
    public Flux<JobResponse> streamJobs() {
        return jobService.getAllJobs()
            .delayElements(Duration.ofMillis(100));  // Streaming
    }
    
    @GetMapping("/{id}")
    public Mono<JobResponse> getJob(@PathVariable Long id) {
        return jobService.getJob(id);
    }
    
    @PostMapping
    public Mono<JobResponse> createJob(@RequestBody JobRequest request) {
        return jobService.createJob(request);
    }
}
```

**Backpressure Handling:**

```java
// Consumer can't keep up with producer
Flux<Job> jobs = jobRepository.findAll()
    .onBackpressureBuffer(100)  // Buffer 100 items
    .onBackpressureDrop()       // Drop excess items
    .onBackpressureLatest();    // Keep only latest
```

**Error Handling:**

```java
public Mono<Job> getJob(Long id) {
    return jobRepository.findById(id)
        .switchIfEmpty(Mono.error(new NotFoundException("Job not found")))
        .onErrorResume(e -> {
            log.error("Error fetching job", e);
            return Mono.just(Job.getDefaultJob());
        })
        .retry(3)  // Retry on failure
        .timeout(Duration.ofSeconds(5));  // Timeout
}
```

**When to Use WebFlux:**

**Use WebFlux When:**
‚úÖ High concurrency (10k+ concurrent requests)
‚úÖ I/O intensive operations
‚úÖ Streaming data (SSE, WebSocket)
‚úÖ Microservices with many external calls
‚úÖ Limited resources (cloud, containers)

**Use Spring MVC When:**
‚úÖ CRUD applications
‚úÖ Blocking dependencies (JDBC)
‚úÖ Team not familiar with reactive
‚úÖ Simple request-response
‚úÖ Low to medium traffic

**Performance Comparison:**

```
Scenario: 10,000 concurrent requests

Spring MVC:
- Threads: 10,000
- Memory: ~10 GB
- Response time: 2s
- Throughput: 5,000 req/s

Spring WebFlux:
- Threads: 8 (CPU cores)
- Memory: ~500 MB
- Response time: 200ms
- Throughput: 50,000 req/s
```

**Converting My Project to WebFlux:**

```java
// Current (MVC)
@Repository
public interface JobRepository extends JpaRepository<Job, Long> {}

// WebFlux
@Repository
public interface JobRepository extends ReactiveMongoRepository<Job, Long> {}

// Current (MVC)
@FeignClient(name = "AUTH-SERVICE")
public interface AuthServiceClient {
    @GetMapping("/api/auth/users/{id}")
    User getUser(@PathVariable Long id);
}

// WebFlux
@Bean
public WebClient authServiceClient() {
    return WebClient.builder()
        .baseUrl("http://AUTH-SERVICE")
        .build();
}

public Mono<User> getUser(Long id) {
    return authServiceClient
        .get()
        .uri("/api/auth/users/{id}", id)
        .retrieve()
        .bodyToMono(User.class);
}
```

**Challenges:**
- Learning curve (Mono/Flux thinking)
- Debugging harder (stack traces less useful)
- Need reactive database drivers
- Not all libraries support reactive
- Testing more complex

**My Decision:**

"I used Spring MVC because:
1. CRUD operations fit MVC better
2. Using JPA with H2 (blocking)
3. Simpler for demonstration
4. Team familiarity

For a high-traffic system (job search with millions of users), I'd use WebFlux with:
- MongoDB (reactive driver)
- WebClient for service calls
- Server-Sent Events for real-time notifications
- Reactive RabbitMQ

This would handle 10x more traffic with same resources."

---

### Q31: CQRS and Event Sourcing

**Your Answer:**

"CQRS and Event Sourcing are advanced patterns for complex domains.

**CQRS (Command Query Responsibility Segregation):**

**Concept:** Separate read and write operations

**Traditional Approach:**
```
Client ‚Üí Single Model ‚Üí Database
         (read & write)
```

**CQRS Approach:**
```
Client ‚Üí Command Model ‚Üí Write DB (PostgreSQL)
         (Create, Update, Delete)

Client ‚Üí Query Model ‚Üí Read DB (Elasticsearch)
         (Search, Filter, Get)
```

**Implementation:**

```java
// Write Side (Commands)
@Service
public class JobCommandService {
    
    @Autowired
    private JobWriteRepository writeRepository;
    
    @Autowired
    private EventPublisher eventPublisher;
    
    public Job createJob(CreateJobCommand command) {
        Job job = Job.builder()
            .title(command.getTitle())
            .description(command.getDescription())
            .build();
        
        Job savedJob = writeRepository.save(job);
        
        // Publish event
        eventPublisher.publish(new JobCreatedEvent(savedJob));
        
        return savedJob;
    }
    
    public void updateJob(UpdateJobCommand command) {
        Job job = writeRepository.findById(command.getJobId());
        job.update(command);
        writeRepository.save(job);
        
        eventPublisher.publish(new JobUpdatedEvent(job));
    }
}

// Read Side (Queries)
@Service
public class JobQueryService {
    
    @Autowired
    private JobReadRepository readRepository;  // Optimized for reads
    
    public JobView getJob(Long id) {
        return readRepository.findById(id);
    }
    
    public List<JobView> searchJobs(String keyword) {
        return readRepository.search(keyword);  // Uses Elasticsearch
    }
    
    public List<JobView> getJobsByCategory(String category) {
        return readRepository.findByCategory(category);
    }
}

// Event Handler (Updates Read Model)
@Service
public class JobEventHandler {
    
    @Autowired
    private JobReadRepository readRepository;
    
    @EventListener
    public void handle(JobCreatedEvent event) {
        JobView view = JobView.from(event.getJob());
        readRepository.save(view);
    }
    
    @EventListener
    public void handle(JobUpdatedEvent event) {
        JobView view = readRepository.findById(event.getJobId());
        view.update(event);
        readRepository.save(view);
    }
}
```

**Benefits of CQRS:**
- **Independent Scaling:** Scale reads and writes separately
- **Optimized Models:** Write model for consistency, read model for performance
- **Technology Flexibility:** SQL for writes, Elasticsearch for reads
- **Complex Queries:** Denormalized read models for fast queries

**Event Sourcing:**

**Concept:** Store events instead of current state

**Traditional Approach:**
```
Database stores current state:
Job { id: 1, title: "Java Developer", status: "ACTIVE" }

History lost when updated
```

**Event Sourcing Approach:**
```
Store sequence of events:
1. JobCreated { id: 1, title: "Java Developer" }
2. JobTitleChanged { id: 1, newTitle: "Senior Java Developer" }
3. JobActivated { id: 1 }

Current state = replay all events
Complete audit trail
```

**Implementation:**

```java
// Event Store
@Entity
public class JobEvent {
    @Id
    private Long id;
    private Long jobId;
    private String eventType;
    private String eventData;  // JSON
    private LocalDateTime timestamp;
    private Long version;
}

// Aggregate (Job)
public class JobAggregate {
    private Long id;
    private String title;
    private String description;
    private JobStatus status;
    private List<JobEvent> events = new ArrayList<>();
    
    // Apply event to change state
    public void apply(JobCreatedEvent event) {
        this.id = event.getJobId();
        this.title = event.getTitle();
        this.status = JobStatus.DRAFT;
        events.add(new JobEvent("JobCreated", event));
    }
    
    public void apply(JobActivatedEvent event) {
        this.status = JobStatus.ACTIVE;
        events.add(new JobEvent("JobActivated", event));
    }
    
    // Command handler
    public void activate() {
        if (this.status != JobStatus.DRAFT) {
            throw new IllegalStateException("Only draft jobs can be activated");
        }
        apply(new JobActivatedEvent(this.id));
    }
    
    // Rebuild state from events
    public static JobAggregate fromEvents(List<JobEvent> events) {
        JobAggregate job = new JobAggregate();
        events.forEach(event -> {
            switch (event.getEventType()) {
                case "JobCreated":
                    job.apply(event.deserialize(JobCreatedEvent.class));
                    break;
                case "JobActivated":
                    job.apply(event.deserialize(JobActivatedEvent.class));
                    break;
            }
        });
        return job;
    }
}

// Repository
@Repository
public class JobEventRepository {
    
    public void save(JobAggregate job) {
        job.getEvents().forEach(event -> {
            eventStore.save(event);
        });
    }
    
    public JobAggregate findById(Long jobId) {
        List<JobEvent> events = eventStore.findByJobId(jobId);
        return JobAggregate.fromEvents(events);
    }
}

// Service
@Service
public class JobService {
    
    @Autowired
    private JobEventRepository repository;
    
    public void activateJob(Long jobId) {
        JobAggregate job = repository.findById(jobId);
        job.activate();  // Generates JobActivatedEvent
        repository.save(job);
    }
}
```

**Snapshots (Performance Optimization):**

```java
// Instead of replaying 10,000 events every time
// Take snapshot every 100 events

@Entity
public class JobSnapshot {
    @Id
    private Long id;
    private Long jobId;
    private String state;  // Serialized job state
    private Long version;  // Event version at snapshot time
}

public JobAggregate fromEventsWithSnapshot(Long jobId) {
    JobSnapshot snapshot = snapshotRepository.findLatest(jobId);
    
    if (snapshot != null) {
        JobAggregate job = snapshot.deserialize();
        List<JobEvent> newEvents = eventStore.findByJobIdAfterVersion(
            jobId, snapshot.getVersion()
        );
        newEvents.forEach(job::apply);
        return job;
    } else {
        List<JobEvent> allEvents = eventStore.findByJobId(jobId);
        return JobAggregate.fromEvents(allEvents);
    }
}
```

**CQRS + Event Sourcing Combined:**

```
Write Side:
Command ‚Üí Aggregate ‚Üí Events ‚Üí Event Store
                          ‚Üì
                    Event Bus
                          ‚Üì
Read Side:
Events ‚Üí Update Read Models ‚Üí Query Database
```

**When to Use:**

**Use CQRS When:**
‚úÖ Complex read requirements (different views of data)
‚úÖ Read/write ratio very different (1000:1)
‚úÖ Need independent scaling
‚úÖ Multiple read models needed

**Use Event Sourcing When:**
‚úÖ Audit trail required (financial, medical)
‚úÖ Temporal queries ("state at time X")
‚úÖ Event replay needed
‚úÖ Complex business logic

**Don't Use When:**
‚ùå Simple CRUD application
‚ùå Small team (high complexity)
‚ùå No audit requirements
‚ùå Database sufficient for queries

**My Project:**

"Currently using traditional CRUD. I'd add CQRS/Event Sourcing if:

**CQRS for Job Search:**
- Write side: PostgreSQL (job data)
- Read side: Elasticsearch (optimized search)
- 1000x more searches than job posts

**Event Sourcing for Applications:**
- Track complete application journey
- Audit trail: APPLIED ‚Üí REVIEWED ‚Üí SHORTLISTED ‚Üí INTERVIEWED ‚Üí ACCEPTED
- Allow questions: 'How many applications in each stage on Jan 15?'
- Compliance requirements

But for current scale, traditional approach is simpler and sufficient."

---

## üõ†Ô∏è Troubleshooting Scenarios

### Q32: "Database connection pool exhausted. How do you fix it?"

**Your Answer:**

"This means all database connections are in use and new requests are waiting.

**Diagnosis:**

```bash
# Check logs
docker-compose logs job-service | grep "Connection"

# Check Hikari metrics
curl http://localhost:8082/actuator/metrics/hikaricp.connections.active
curl http://localhost:8082/actuator/metrics/hikaricp.connections.pending
```

**Common Causes:**

**1. Not Closing Connections (Connection Leak):**

```java
// Bad (connection leak)
@Service
public class BadJobService {
    @Autowired
    private DataSource dataSource;
    
    public Job getJob(Long id) {
        Connection conn = dataSource.getConnection();
        // Query database
        // FORGOT TO CLOSE CONNECTION!
        return job;
    }
}

// Good (using JPA - auto-closes)
@Service
public class GoodJobService {
    @Autowired
    private JobRepository repository;
    
    public Job getJob(Long id) {
        return repository.findById(id).orElse(null);
        // JPA handles connection lifecycle
    }
}
```

**2. Long-Running Transactions:**

```java
// Bad (holds connection for 10 seconds)
@Transactional
public void processJobs() {
    List<Job> jobs = jobRepository.findAll();
    
    for (Job job : jobs) {
        // Heavy processing - 10 seconds
        analyzeJob(job);
    }
    // Connection held entire time
}

// Good (minimize transaction scope)
public void processJobs() {
    List<Job> jobs = jobRepository.findAll();  // Quick query
    
    for (Job job : jobs) {
        processJob(job);  // Each has own transaction
    }
}

@Transactional
public void processJob(Job job) {
    // Process single job
    jobRepository.save(job);
}
```

**3. Pool Too Small:**

```yaml
# Current (too small)
spring:
  datasource:
    hikari:
      maximum-pool-size: 10

# Fixed (appropriate size)
spring:
  datasource:
    hikari:
      maximum-pool-size: 20  # 2x CPU cores
      minimum-idle: 5
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
```

**Calculation:**
```
Pool size = ((core_count * 2) + effective_spindle_count)
Example: (4 cores * 2) + 1 = 9 connections

But monitor and adjust based on actual usage
```

**4. Slow Queries:**

```bash
# Enable query logging
spring.jpa.show-sql=true
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.use_sql_comments=true

# Check slow queries
# Look for queries taking > 100ms
```

**Solutions:**

```java
// Add indexes
@Entity
@Table(indexes = {
    @Index(name = "idx_category", columnList = "category"),
    @Index(name = "idx_posted_by", columnList = "postedBy")
})
public class Job {
    // fields
}

// Use pagination
Pageable pageable = PageRequest.of(0, 20);
Page<Job> jobs = jobRepository.findAll(pageable);

// Use projections (don't fetch all fields)
public interface JobSummary {
    Long getId();
    String getTitle();
    // Only needed fields
}

List<JobSummary> jobs = jobRepository.findAllProjectedBy();
```

**5. Monitor Connection Pool:**

```java
@Component
public class HikariMonitor {
    
    @Autowired
    private HikariDataSource dataSource;
    
    @Scheduled(fixedRate = 60000)
    public void logPoolStats() {
        HikariPoolMXBean pool = dataSource.getHikariPoolMXBean();
        
        log.info("Hikari Pool Stats:");
        log.info("Active: {}", pool.getActiveConnections());
        log.info("Idle: {}", pool.getIdleConnections());
        log.info("Waiting: {}", pool.getThreadsAwaitingConnection());
        log.info("Total: {}", pool.getTotalConnections());
    }
}
```

**Prevention:**
- Use JPA/Spring Data (handles connections properly)
- Keep transactions short
- Add indexes for common queries
- Monitor connection pool metrics
- Set appropriate pool size
- Use connection timeout

This demonstrates understanding of database connections and performance tuning."

---

## üí° What Would You Improve?

### Q33: "What would you add/improve in your project?"

**Your Answer:**

"Given more time and for production readiness, I'd add:

**1. Production Database:**
- Replace H2 with PostgreSQL/MySQL
- Implement Flyway/Liquibase for migrations
- Setup read replicas for scaling

**2. Caching Layer:**
```java
@Cacheable("jobs")
public Job getJob(Long id) {
    return jobRepository.findById(id);
}

// Redis configuration
spring.cache.type=redis
spring.redis.host=localhost
spring.redis.port=6379
```

**3. Circuit Breaker:**
```java
@CircuitBreaker(name = "authService", fallbackMethod = "fallback")
public User getUser(Long id) {
    return authServiceClient.getUser(id);
}
```

**4. API Versioning:**
```java
@RestController
@RequestMapping("/api/v1/jobs")
public class JobControllerV1 {
}

@RestController
@RequestMapping("/api/v2/jobs")
public class JobControllerV2 {
}
```

**5. Comprehensive Testing:**
```java
// Unit tests
// Integration tests
// Contract tests (Pact)
// Load tests (JMeter, Gatling)
// Chaos engineering (breaking services intentionally)
```

**6. API Documentation:**
```java
@Operation(summary = "Create job", description = "Creates a new job posting")
@ApiResponses(value = {
    @ApiResponse(responseCode = "201", description = "Job created"),
    @ApiResponse(responseCode = "401", description = "Unauthorized")
})
@PostMapping("/api/jobs")
public JobResponse createJob(@RequestBody JobRequest request) {
}
```

**7. Distributed Tracing:**
- Add Zipkin/Jaeger
- Track requests across services
- Identify bottlenecks

**8. Centralized Configuration:**
- Spring Cloud Config Server
- Externalize all configs
- Environment-specific configs

**9. Message Retry & DLQ:**
```java
@RabbitListener(queues = "job.posted.queue")
public void handleJobPosted(JobPostedEvent event) {
    try {
        sendNotifications(event);
    } catch (Exception e) {
        // Retry 3 times, then send to dead letter queue
        throw new AmqpRejectAndDontRequeueException(e);
    }
}
```

**10. Security Enhancements:**
- Refresh tokens
- OAuth2 integration
- Rate limiting
- HTTPS/TLS
- Input sanitization

This shows I understand the project is a learning prototype and what production systems need."

---

## üéì Final Tips

**Interview Preparation Checklist:**

- ‚úÖ Practice 30-second project pitch
- ‚úÖ Draw architecture diagram by hand
- ‚úÖ Explain each service's purpose
- ‚úÖ Know JWT flow by heart
- ‚úÖ Understand RabbitMQ event flow
- ‚úÖ Prepare metrics (70% reduction, 99% uptime)
- ‚úÖ Know trade-offs (why microservices vs monolith)
- ‚úÖ Understand what you'd improve
- ‚úÖ Be ready for "what if" scenarios
- ‚úÖ Have GitHub link ready with README

**Common Follow-up Questions:**
- "Why this technology over alternatives?"
- "How would you scale this to 1M users?"
- "What happens if service X fails?"
- "How do you ensure data consistency?"
- "Walk me through the complete request flow"

**Remember:**
- Be honest if you don't know something
- Relate answers to your actual implementation
- Use real examples from your code
- Show enthusiasm for learning
- Discuss trade-offs, not just benefits

---

<div align="center">

**Good luck with your interviews!** üéØ

*Practice explaining your project until you can do it in your sleep.*

</div>